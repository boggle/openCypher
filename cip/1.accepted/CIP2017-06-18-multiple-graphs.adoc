= CIP2017-06-18 Multiple Graphs
:numbered:
:toc:
:toc-placement: macro
:source-highlighter: codemirror

*Author:* Stefan Plantikow <stefan.plantikow@neotechnology.com>

This material is based on internal contributions of Alastair Green <alastair.green@neotechnology.com>, Mats Rydberg <mats.rydberg@neotechnology.com>, Martin Junghanns <martin.junghanns@neotechnology.com>, Tobias Lindaaker <tobias.lindaaker@neotechnology.com>, Petra Selmer <petra.selmer@neotechnology.com>

[abstract]
.Abstract
--
// This CIP proposes extending Cypher to support the construction, transformation, and querying of multiple graphs by adopting (i) the proposed multiple property graphs model, (ii) the proposed multiple graphs execution model, and (iii) by introducing new syntax for working with multiple graphs.
* Graph data model
* Id/stability
* Graph catalog and related operations
* Selecting and using the working graph
* Returning a graph
* Projecting graphs
* Scalar subqueries
* Nested subqueries
* Graph UNION
* Named queries in catalog and locally
* Named graphs in catalog and locally
* Equivalence (expressions)
* Syntactic units / queries/ DDL chaining (stmt1; stm2)
--

toc::[]

== Motivation

Cypher today is a query language for property graphs that provides access to a single, global, implicit graph in order to extract, transform, and return tabular data that is derived from it.
While such returned tabular data may include graph entities (such as nodes and relationships), in essence Cypher as a language is not closed under graphs and as a consequence, Cypher queries are not yet (graph) compositional.

However it seems desirable that a language for property graphs should not only enable querying and updating a selected graph but should also support the construction and transformation of multiple graphs, ideally by utilizing a mechanism for incremental query composition.

Furthermore, adding support for working with multiple graphs has recently been identified as a frequently requested feature:

* It would enable the dynamic construction of graph views (e.g. for access control)
* It would allow reasoning over multiple versions of the same graph (e.g. comparing daily snapshots)
* It would provide an effective grouping mechanism for naturally-partitioned data (e.g. per-continent graph)
* It could be used for combining data from disparate data sources in one system (e.g. in federation and data integration scenarios)
* It fits the paradigm of prominent analytical big-data processing systems (e.g. Apache Spark)
* It mirrors mathematical graph theory where working with multiple graphs is common

== Query Execution Model

_Definition_: A *query processor* is a query processing service that interacts with clients to execute Cypher statements on their behalf and returns the results of processing back to them.

// Statement = Syntactic Unit
// - Reading query
// - Updating query
// - Updating command
// - Schema command
// - Statement chain


== Multiple Property Graphs Model

Before proposing changes to the language, it is necessary to first address changes required to the underlying https://github.com/opencypher/openCypher/blob/master/docs/property-graph-model.adoc[*property graph model*].

The revised property graph model used in this CIP is called the *multiple property graphs model* and assumes everything specified in the original property graph model is extended with the notion of multiple graphs outlined in the following subsections.

=== Model definition

This CIP defines an instance of the *multiple property graphs model* to be a set of property graphs that adhere to the definitions given below.

=== (Property) Graph

_Definition_: A *property graph* is a set of labeled nodes and typed relationships, where each node and relationship contains zero or more properties (a property is a tuple consisting of a named key and value).
Graphs may be read-only or updatable.

=== Entities

_Definition_: An *entity* is either a node or relationship.
Every entity exists in exactly one property graph.

=== Identities

Identities are regular values that are used to uniquely identify elements of a set of values (called the domain).

The following identity domains are used:
* *node identities* uniquely identify a node within its graph
* *relationship identities* uniquely identify a relationship within its graph
* *graph identities* uniquely identify a graph that is managed by the query processor

Identity values may not be one of the following:
 * Values that either are or include elements of the property graph model (nodes, relationships, paths)
 * `NULL`

Identities are guaranteed to be valid for the duration of executing a statement and consuming it's result.

Note:: The same identity value might reference different elements in results from executing different statements.

Implementations may choose to guarantee the validity of identities across multiple statement executions.

The `graph(e)` function returns the *graph identity* of an entity `e`.

The `id(n)` function returns the *node identity* of a node `n`.

The `id(r)` function returns the *relationship identity* of a relationship `r`.

=== Catalog

// TODO: By reference

A query processor has one *catalog*, which is the part of the system that know how to translate *qualified graph names* to graphs. A fully qualified graph name consists of an optional graph namespace, and a mandatory graph name.

Note:: A query processor might have a catalog shared by all users, or keep one per user.

=== Working graph

Most Cypher clauses operate within the context of a working graph, by reading or updating it.

A query processor may choose to establish an *initial working graph* for each executed statement.
The details of this are left to implementations.

If a query processor has not established an initial working graph and the query does establish a working graph before operating on the working graph, an error is produced.

The working graph may be operated on in the following ways:

* The working graph can be changed by selecting a graph that is known by the catalog.
* The working graph can be changed by constructing a new graph
* The working graph may be returned as a query result

=== Selecting the working graph from the catalog

The working graph may be changed for all subsequent clauses using:

[source, cypher]
----
FROM GRAPH < graph-name >
----

`<graph-name>` is expected to be the name of a graph in the catalog.

If `<graph-name>` is not the name of a graph in the catalog, an error is produced.

=== Returning a graph result

The working graph may be returned as a query result using:

[source, cypher]
----
RETURN GRAPH
----

Additionally, the following syntactic form is supported for selecting the working graph from the catalog and returning it at the same time:

[source, cypher]
----
RETURN GRAPH < graph-name >
----

=== Constructing a graph

Graph construction dynamically constructs a new working graph in a query in order to query it, store it in the catalog, or return it to the client.

Graph construction is the dual operation to graph matching: While graph matching extracts pattern instances into variable bindings from the working graph, graph construction builds a new working graph from variable bindings.

All nodes and relationships in the newly constructed graph have new entity identities and are different from any previously matched entities.

The general form of graph construction is:

[source, cypher]
----
CONSTRUCT
  [ON < graph-name-list >]
  CLONE < cloned-entities >
  NEW < patterns >
  [YIELD < return-items >]
----

Graph construction supports sub-clauses for *cloning of existing entities*, the *addition of new entities*, and *yielding of result variable bindings*.

Either the `CLONE` subclause of the `NEW` sub-clause must be present in `CONSTRUCT`.

A statement must not end in a `CONSTRUCT` clause.

==== Newly constructed entities

The `NEW <patterns>` sub-clause may be used to construct new nodes and relationships in the constructed graph in the same way as the `CREATE` clause allows to create new nodes and relationships in existing graphs.

`NEW` creates exactly one pattern instance in the new graph for each input record.

==== Cloned entities

In order to reconstruct subgraph structures from other graphs in the new graph, `CONSTRUCT` supports the addition of *cloned entities* in the new graph.

Cloning ensures that exactly one (representative) cloned entity is created in the new graph for a given cloned entity.
In particular, if the same input entity is cloned multiple times this will still only create one cloned entity in the new graph.

The `CLONE < return-items >` sub-clause may be used to clone entities and bind the cloned entities to new variable names.
`CLONE` constructs cloned entities for each input record subject to the following rules:

 * Cloning a single, already bound variable rebinds the variable. In other words `CLONE a` is interpreted as `CLONE a AS a`
 * Cloning a relationship implicitly clones its start node and its end node
 * Cloning a path implicitly clones all nodes and relationships of the path

==== Yielding no result variable bindings

If a `CONSTRUCT` clause is not ending in a `YIELD` sub-clause, all variable bindings and the current record cardinality are dropped.
The next clause then proceeds in the newly constructed working graph on a single record with no fields.

==== Yielding result variable bindings

The `YIELD <return-items>` sub-clause may be used to extend the driving table with additional variable bindings.
The `YIELD` sub-clause in `CONSTRUCT` may also be used to shadow existing variable bindings in the driving table.
`YIELD *` may be used to yield variable bindings for all cloned and newly created entities.

<TODO>

=== Creating and administrating graphs in the catalog

Creating a new graph in the catalog is done using the new DDL command `CREATE GRAPH`. `CREATE GRAPH` can be used without a subquery, which results in creating a new graph without any content.
If CREATE GRAPH is followed by a subquery that returns a graph

//
//
// === Graph Addressing
//
// Graphs do not expose an identity in the same way that nodes or relationships do.
//
// Graphs may be made addressable through other means by a conforming implementation, e.g. through exposing the graph via a _graph URL_ for referencing and loading it.
// The details regarding the format and choice of graph URLs is beyond the scope of this proposal.
//
// A graph is considered to have been deleted if it is no longer registered under a graph URL and no other reference to it is retained, e.g. from a running query.
//
// == Background: Single Graph Execution Model
//
// Before detailing the foundational changes proposed by this CIP, we will define some basic terms and concepts for describing the state that is manipulated by Cypher's current single graph execution model.
//
// A Cypher query currently takes a set of parameters as input, queries a single, global, implicit property graph, potentially updates it, and finally returns tabular data derived from it.
// Query parameters are conceptually thought to be inlined before the start of query execution.
// Therefore the *session context* of a whole Cypher query is a single, global, implicit property graph.
//
// Each sequence of clauses (sometimes called a *pipeline*) optionally operates on this single implicit graph and takes a single table input in order to produce a new single table output.
// Furthermore, Cypher supports query combinator clauses like `UNION` and `UNION ALL` for merging two pipelines into a single pipeline.
// Therefore the *query context* that conceptually is passed between clauses in the single graph execution model is simply a single table.
//
// With this terminology in place, execution of a parameterized Cypher query in the single graph execution model can be described as executing within (and operating on) a given session context and an initial query context and finally returning the query context produced as output for the final `RETURN` clause.
//
// NOTE: This formulation is introduced to describe a high-level model for the execution of queries; a real world implementation is free to choose any other internal representation (e.g. based on an algebra) as long as it does not violate the specified semantics.
//
// == Proposal: Multiple Graphs Execution Model
//
// In the single graph execution model, tabular data serves as the basis of iteration while the single implicit global graph serves as the basis of graph matching and graph manipulation.
//
// This section introduces the *multiple graphs execution model* as an evolution of the single graph execution model that enables the addition of features to the language for working with multiple graphs, i.e. it changes the basis of graph matching and graph manipulation.
//
// This CIP proposes the adoption of the multiple graphs execution model by Cypher and to execute existing, single graph queries under this model as outlined below.
//
// === Model definition
//
// This CIP proposes redefining the *session context* to be
//
// * a set of graphs in the multiple graphs execution model
// * a special graph drawn from this set that is called the *default graph*
//
// This CIP proposes redefining the *query context* to be
//
// * a set of named graphs from the *session context*
// * *tabular data*, i.e. a potentially ordered bag of records, each having the same fixed set of fields
// * a special graph drawn from the *session context* that is called the *source graph*
// * a special graph drawn from the *session context* that is called the *target graph*
//
// These redefinitions comprise the multiple graphs execution model.
// A parameterized Cypher query under this model can _also_ be described as executing within (and operating on) a given session context and starting from an initial query context and finally returning the query context produced as output for the final `RETURN` clause.
//
// As a consequence of adopting the new multiple graphs execution model, the semantics of each clause need to be (re-)defined as to how the execution of the clause transforms all given input query contexts into an output query context.
// This CIP preserves all existing semantics by defining how to simulate the single graph execution model in the multiple graphs execution model as outlined below.
//
// === Query composition
//
// The multiple graphs execution model provides a natural way for the sequential composition of queries:
//
// A query `Q1` whose output signature is (in terms of provided bindings) an acceptable input signature for another query `Q2` may be composed sequentially with `Q2` into a new query `Q3` that first runs `Q1` on the initial query context, next runs `Q2` on the query context returned by `Q1`, and finally returns the query context returned by `Q2`.
//
// This homogenous query composition is enabled by using a uniform query context that is passed between clauses.
//
// === Query combinators
//
// Query combinators only need to handle tabular query contexts in the single graph execution model.
//
// For the multiple property graphs execution model, it is necessary to define how query combinators combine the query contexts of all child queries into a new result query context (c.f. query composition).
//
// This CIP proposes that the multi-arm query combinators `UNION` (and `UNION ALL` respectively) combine their contexts according to the following rules:
//
// * Tabular data is combined as today, i.e. the tabular result is either a concatenation (`UNION ALL` case) or a distinct union (`UNION` case) of the tabular data from both arms
// *  All graphs from both arms are returned; if both arms return a graph with the same name, then the union of those graphs is returned under that shared name
// * If both queries have specified a graph with the same name as their current source graph, then the union of those source graphs under that name again becomes the source graph for further processing.
// Otherwise, the default graph becomes the source graph for further processing.
// * If both queries have specified a graph with the same name as their current target graph, then the union of those target graphs under that name again becomes the target graph for further processing.
// Otherwise, the default graph becomes the target graph for further processing.
//
// === Expression evaluation
//
// Expressions are generally evaluated using the source graph of the current query context.
//
// === Updating queries
//
// This CIP proposes the following update semantics for Cypher with support for multiple graphs:
//
// * All updating clauses read from the source graph and write to the target graph of their current query context.
//   More concretely:
//   ** Entities are always created in, updated in, and deleted from the currently provided target graph.
//   ** Variables used in `CREATE` and `MERGE` that have been previously bound will cause the bound entity to be added to the target graph of the current query context.
//   ** `MERGE` uses the source graph to find existing entities.
//   ** Deleting an entity only affects the provided target graph of the current query context.
// * Updating queries behave as if they would end in `RETURN - GRAPHS -` (this syntax is introduced below).
// * Semantically, all effects of an updating clause must be made visible before proceeding with the execution of the next clause.
// In other words, a conforming implementation must ensure that a later clause always sees the complete set of updates of a preceding updating clause.
//
// This CIP proposes allowing `MERGE` to be followed by a non-empty, comma-separated list of bound variables for explicitly adding entities to the target graph.
//
// === Simulating the single graph execution model
//
// Execution under the single graph execution model can be simulated in the multiple graphs execution model by executing the query in an session context that uses the single graph as the default graph, and by running it on an empty initial query context.
//
// == Proposal: Multiple Graphs Syntax
//
// This CIP first proposes new syntactical concepts before proceeding to add new and extend existing clauses.
//
// === Named graphs
//
// Here we introduce the notion of _named graphs_.
// The name of a graph is used to reference the graph in the query context.
// Graph names are denoted here with `<graph-name>`, and use the same syntax as normal variables.
//
// NOTE: Graph names live in the same namespace as variables, thus it is an error to define a graph with a name of a previously existing variable, and vice versa.
//
// ==== Graph references and aliases
//
// An explicit reference to a graph is simply the name of the graph.
// A _graph alias_ is a graph reference optionally followed by `AS <graph-name>`, denoted here as `<graph-alias>`.
// A _graph alias list_ is a comma-separated list of graph aliases, denoted here as `<graph-alias-list>`.
//
// ==== Resolving external graphs
//
// Graphs are loaded into the query context by resolving a given graph URL in _graph URL subclause_.
// Graph URL subclauses are on the form `AT <graph-url>` or `TO <graph-url>`, where the exact shape and form of `<graph-url>` lies outside the scope of this CIP.
// However, this CIP proposes that a graph URL should be given as either a string literal or a query parameter, in order to give a query planner static knowledge of loaded graphs, and allowing queries to be parametrised on its input and output graphs.
//
// ==== Graph definitions
//
// Let `<graph-def>` denote a _graph definition_, which is a construct used to introduce additional named graphs.
//
// There are three kinds of graph definitions:
//
// * _new_ graph definitions, denoted by `<new-graph-def>`,
// * _collecting_ graph definitions, denoted by `<collect-graph-def>`,
// * _aliasing_ graph definitions, denoted by `<alias-graph-def>`.
//
// Many graph definitions allow an optional graph url subclause, where optionality is denoted using `[]`.
//
// New graph definitions always introduce a new graph:
//
// * `NEW GRAPH <graph-name> [AT <graph-url]`: Defines an empty graph with name `<graph-name>`, optionally published at `<graph-url>`.
// * `COPY GRAPH <graph-name> FROM <graph-ref> [TO <graph-url>]`: Defines a copy of the graph given by `<graph-ref>` with name `<graph-name>`, optionally published at `<graph-url>`.
// A copied graph shares the same entities of its original.
// * `CLONE GRAPH <graph-name> FROM <graph-ref> [TO <graph-url>]`: Same as `COPY`, except entities are also copied instead of shared.
// * `GRAPH <graph-name> AT <graph-url>`: Defines a graph with name `<graph-name>` loaded from the given `<graph-url>`.
//
// Collecting graph definitions are on the form `GRAPH <graph-name> OF <match-pattern> [AT <graph-url>]` and defines a graph newly constructed from tabular input records by collecting all entities from bound variables and creating new entities for all unbound variables in the patterns given in `<match-pattern>`, optionally published at `<graph-url>`.
//
// Aliasing graph definitions `<alias-graph-def>` alias an existing graph under a new name:
//
// * `GRAPH <graph-alias> [AT <graph-url>]` (i.e. `GRAPH <graph-ref> AS <new-graph-name> [AT <graph-url>]`): A new alias for an existing graph, optionally published at `<graph-url>`.
// * `SOURCE GRAPH AS <new-graph-name> [AT <graph-url>]`: An alias for the current _source graph_.
// * `TARGET GRAPH AS <new-graph-name> [AT <graph-url>]`: An alias for the current _target graph_.
// * `DEFAULT GRAPH AS <new-graph-name> [AT <graph-url>]`: An alias for the current _default graph_.
//
// This CIP defines the notion of an optional graph definition `<opt-graph-def>` that does not provide a `<new-graph-name>` and does not contain a subclause of the form `[AT|TO] <graph-url>` for aliasing graph definitions.
//
// `GRAPH <match-pattern>` is proposed to be a shorthand for the valid optional graph definition of the form `GRAPH OF <match-pattern>`
//
// ==== Graph specifiers
//
// This CIP defines the notion of a graph specifier `<graph-spec>` to be either a `<graph-def>` or an `<opt-graph-def>`.
//
// === Introducing multiple graphs
//
// As a first language addition, this CIP proposes syntax for introducing graphs into the current query context:
//
// [source, cypher]
// ----
// FROM < graph-spec >
// INTO < graph-spec >
// ----
//
// ==== FROM clause: Change the source and the target graph
//
// This CIP proposes a new `FROM` clause to change both the source and the target graph of the current query context as described.
//
// ==== INTO clause: Change the target graph only
//
// This CIP proposes a new `INTO` clause to change the target graph of the current query context as described.
//
// === THEN clause: Discarding available tabular data
//
// This CIP additionally proposes a new `THEN` clause that may be used for passing on all named graphs while discarding all tabular data such that the tabular input for the following clause (or query respectively) becomes a single record without any fields.
//
// NOTE: This syntax may be used to indicate when the gradual construction of a named graph is finished since neither fields nor the cardinality of tabular data is preserved after this point.
//
// === Returning, aliasing, and selecting graphs
//
// This CIP proposes to extend both the `WITH` and the `RETURN` clauses with new syntax for controlling the set of available named graphs that should be passed on by the clause (or returned from the query respectively) by explicitly specifying all `<graph-return-items>`.
// The newly proposed syntax is:
//
// [source, cypher]
// ----
// WITH < return-items > < graph-return-items >
// WITH < graph-return-items >
// RETURN < return-items > < graph-return-items >
// WITH < graph-return-items >
// ----
//
// This CIP defines that `<graph-return-items>` is either just `GRAPHS -` for indicating that all named graphs currently in scope are to be discarded or a space-separated list of:
//
// *  `<graph-def>`: to indicate that the defined graph is to be passed on,
// * `GRAPHS *`: to indicate that all named graphs currently in scope are to be passed on,
// * `GRAPHS <graph-alias-list>`: to indicate that all explicitly listed named graphs are to be passed on.
//
// Both `WITH ... GRAPHS ...` and `RETURN ... GRAPHS ...` will pass on (or return respectively) exactly the set of graphs described by `<graph-return-items>`.
//
// `GRAPHS *, <graph-alias-list>` is proposed to be a shorthand for `GRAPHS * GRAPHS <graph-alias-list>`.
// This forms indicates that all named graphs currently in scope together with any additionally introduced named graphs from `<graph-alias-list>` are to be passed on.
// It is an error if this leads to shadowing of already bound named graphs by newly introduced named graphs.
// Similarly, `GRAPHS <graph-alias-list>, *` is proposed to be a shorthand for `GRAPHS <graph-alias-list> GRAPHS *`.
//
// The order of named graphs inherently given by `<graph-return-items>` is otherwise semantically insignificant.
// However it is recommended that conforming implementations preserve this order at least in programmatic output operations (e.g. a textual display of the list of returned graphs).
// This in essence mirrors the semantics for tabular data returned by Cypher.
//
// Furthermore, this CIP proposes the following shorthands:
//
// * `WITH <return-items>` is to be a shorthand for `WITH <return-items> GRAPHS *`
// * `WITH <graph-return-items>` is to be a shorthand for `THEN WITH - <graph-return-items>`
// * `RETURN <return-items>` is to be a shorthand for `RETURN <return-items> GRAPHS -`
// * `RETURN <graph-return-items>` is to be a shorthand for `THEN RETURN - <graph-return-items>`
//
// === Selecting context graphs from projections
//
// It is proposed that at most once either the `<new-graph-name>` of a named graph described by a `<graph-return-item>`  may be prefixed with the keyword `SOURCE` or the keyword `GRAPH` in a `<graph-def>` should be replaced with `SOURCE GRAPH` to indicate that the described graph should be set as new source and target graph of the next clause.
//
// It is proposed that a `<graph-return-item>` of the form `<opt-graph-def>` is a shorthand for setting the new source graph and target graph of the next clause.
//
// It is proposed that at most once either the `<new-graph-name>` of a named graph described by a `<graph-return-item>`  may be prefixed with the keyword `TARGET` or the keyword `GRAPH` in a `<graph-def>` should be replaced with `TARGET GRAPH` to indicate that the described graph should be set as new target graph of the next clause.
//
// It is propsed that specifying a target graph this way overrides any specification of a source graph given in the same projection clause.
//
// === Query signature declarations
//
// Finally this CIP proposed using the `WITH` clause as the initial clause in a query for declaring all query inputs.
//
// It is proposed that using `WITH` as the initial clause in a query is to be called a *query input declaration* while the use of `RETURN` as the last clause is to be called a *query output declaration*.
//
// Query input declarations are subject to the following limitations:
//
// * All expected tabular input arguments must be given as simple variables
// * All expected graph input arguments should be given as graph return items for named graphs only
// * If the input query context provides additional, undeclared variables or graphs, those inputs are to be silently discarded
//
// A query that does not start with a query input declaration is assumed to start with `WITH - GRAPHS -`.
//
// == Grammar
//
// Proposed syntax changes
// [source, ebnf]
// ----
// // TODO
// ----
//
// == Examples
//
// The following examples are intended to show how multiple graphs may be used, and focus on syntax.
// We show two fully worked-through examples <<data-integration-example, here>> and <<data-aggregation-example, here>>, describing and illustrating every step of the pipeline in detail.
//
// === A template for a multiple graph pipeline
// [source, cypher]
// ----
// // Query input signature: Records with fields 'a', 'b' and two graphs 'g1', 'g2'
// WITH a, b GRAPHS g1, g2
//
// // Sets source and target graph for the following statements by resolving the given physical address
// // (The name of this new graph will be system generated)
// FROM GRAPH AT 'graph://...'
//
// // Creates and sets new target graph for the following statements at the given physical address
// INTO NEW GRAPH result AT 'graph://...'
//
// // Return records with 'a', 'b' and three graphs 'result', 'g1', 'g2' (query output signature)
// // Source graph for future reads is again the default graph, the target graph for future writes is 'result'
// RETURN a, b GRAPHS result, g1, g2
// ----
//
// === A template for pipelining and interleaving queries
//
// [source, cypher]
// ----
// WITH a, b GRAPHS g1, g2 ... // First query
// WITH GRAPHS g3, g4 ...      // Second query over first query
// RETURN c, d GRAPHS g5       // Third query over second query over first query
// ----
//
// === Creating and returning a new graph and fields: a simple example
//
// [source, cypher]
// ----
// FROM GRAPH persons AT 'graph://...'
// MATCH (a:Person)-[r:KNOWS]->(b:Person)
// MATCH (a)-[:LIVES_IN->(c:City)<-[:LIVES_IN]-(b)
// INTO NEW GRAPH berlin
// CREATE (a)-[:FRIEND]->(b) WHERE c.name = "Berlin"
// INTO NEW GRAPH santiago
// CREATE (a)-[:FRIEND]->(b) WHERE c.name = "Santiago"
// FROM DEFAULT GRAPH
// RETURN c.name AS city, count(r) AS num_friends GRAPHS berlin, santiago
// ----
//
// === Creating a new graph, switching contexts and returning a graph
//
// [source, cypher]
// ----
// // Set scope to whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data
// MATCH (a:Person)-[:KNOWS]->(b:Person)-[:KNOWS]->(c:Person) WHERE NOT (a)--(c)
//
// // Create a temporary named graph,
// INTO NEW GRAPH recommendations
// // containing existing nodes and new rels ...
// CREATE (a)-[:POSSIBLE_FRIEND]->(c)
// // ... and finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// // Switch context to named graph.
// FROM GRAPH recommendations
// MATCH (a:Person)-[e:POSSIBLE_FRIEND]->(b:Person)
// // Return tabular and graph output
// RETURN a.name, b.name, count(e) AS cnt
//     ORDER BY cnt DESC
//     GRAPH recommendations
// ----
//
// === Using a pipeline of temporary graphs to process and return a subgraph
//
// [source, cypher]
// ----
// // Set scope to the whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data.
// MATCH (a:Person)-[:IS_LOCATED_IN]->(c:City),
//       (c)->[:IS_LOCATED_IN]->(co:Country),
//       (a)-[e:KNOWS]-(b)
//
// // Create a new temporary named graph,
// INTO NEW GRAPH sn_updated
// // add previous matches to new graph,
// CREATE (a)-[e]-(b)
// // update existing nodes.
// SET a.country = cn.name
// // ... and finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// FROM GRAPH sn_updated
// MATCH (a:Person)-[e:KNOWS]->(b:Person)
// WITH a.country AS a_country, b.country AS b_country, count(a) AS a_cnt, count(b) AS b_cnt, count(e) AS e_cnt
// INTO NEW GRAPH rollup
// MERGE (:Persons {country: a_country, cnt: a_cnt})-[:KNOW {cnt: e_cnt}]->(:Persons {country: b_country, cnt: b_cnt})
//
// // Return final graph output
// RETURN GRAPH rollup
// ----
//
// === A more complex pipeline: using and persisting multiple graphs
//
// [source, cypher]
// ----
// // Set scope to the whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data.
// MATCH (a:Person)-[e]->(b:Person),
//       (a)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c:Country {name: ‘Sweden’}),
//       (b)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c)
// // Create a persistent graph at 'graph://social-network/swe'
// INTO NEW GRAPH sweden_people AT './swe'
// // connecting persons that live in the same city in Sweden.
// CREATE (a)-[e]->(b)
//
// // Finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// MATCH (a:Person)-[e]->(b:Person),
//       (a)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c:Country {name: ‘Germany’}),
//       (b)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c)
// // Create a persistent graph at 'graph://social-network/ger'
// INTO NEW GRAPH german_people AT './ger'
// // connecting persons that live in the same city in Germany.
// CREATE (a)-[e]->(b)
//
// // Finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// // Start query on the 'sweden_people' graph
// FROM GRAPH sweden_people
// MATCH p=(a)--(b)--(c)--(a) WHERE NOT (a)--(c)
// // Create a temporary graph 'swedish_triangles'
// INTO NEW GRAPH swedish_triangles
// MERGE p
//
// // and return it together with a count of its content
// RETURN count(p) AS num_triangles GRAPHS swedish_triangles, sweden_people, german_people
// ----
//
// [[data-integration-example]]
// === A complete example illustrating a data integration scenario
//
// Assume we have two graphs, *ActorsFilmsCities* and *Events*, each of which is contained in a separate location.
// This example will show how these two graphs can be integrated into a single graph.
//
// The *ActorsFilmsCities* graph models the following entities:
//
// * Actors and people fulfilling other roles in the film-industry.
// * Films in which they acted, or directed, or for which they wrote the soundtrack.
// * Cities in which they were born.
// * The relationships between family members and colleagues.
//
// Each node is labelled and contains one or two properties (where `YOB` stands for 'year of birth'), and each relationship of type `ACTED_IN` has a `charactername` property indicating the name of the character the relevant `Actor` played in the `Film`.
//
// image::opencypher-PersonActorCityFilm-graph.jpg[Graph,800,650]
//
// The other graph, *Events*, models information on events.
// Each event is linked to an event type by an `IS_A` relationship, to a year by an `IN_YEAR` relationship, and to a city by an `IN_CITY` relationship.
// For example, the _Battle of Britain_ event is classified as a _War Event_, occurred in the year _1940_, and took place in _London_.
//
// In contrast to the *ActorsFilmsCities* graph, *Events* contains no labels on any node, no properties on any relationship, and only a single `value` property on each node.
// *Events* can be considered to be a snapshot of data from an RDF graph, in the sense that every node has one and only one value; i.e. in contrast to a property graph, an RDF graph has properties on neither nodes nor relationships.
// (For easier visibility, we have coloured accordingly the cities and city-related relationships, event types and event-type relationships, and year and year-related relationships.)
//
// image::opencypher-Events-graph.jpg[Graph,800,600]
//
// The aims of the data integration exercise are twofold:
//
// * Create and persist to disk (for future use) a new graph, *PersonCityEvents*, containing an amalgamation of data from *ActorsFilmsCities* and *Events*.
// *PersonCityEvents* must contain all the event information from *Events*, and only `Person` nodes connected to `City` nodes from *ActorsFilmsCities*.
//
// * Create and return a temporary graph, *Temp-PersonCityCrimes*.
// *Temp-PersonCityCrimes* must contain a subset of the data from *PersonCityEvents*, consisting only of the criminal events, their associated `City` nodes, and `Person` nodes associated with the `City` nodes.
//
// ==== Step 1
//
// The first action to take in our data integration exercise is to set the source graph to *ActorsFilmsCities*, for which we need to provide the physical address:
//
// [source, cypher]
// ----
// FROM GRAPH ActorsFilmsCities AT 'graph://actors_films_cities...'
// ----
//
// Next, match all `Person` nodes who have a `BORN_IN` relationship to a `City`:
//
// [source, cypher]
// ----
// MATCH (p:Person)-[:BORN_IN]->(c:City)
// ----
//
// Create the new graph *PersonCityEvents*, persist it to _some-location_, and set it as the target graph:
//
// [source, cypher]
// ----
// INTO NEW GRAPH PersonCityEvents AT 'some-location'
// ----
//
// Write the subgraph induced by the `MATCH` clause above into *PersonCityEvents*:
//
// [source, cypher]
// ----
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (p)-[:BORN_IN]->(c)
// ----
//
// Putting all these statements together, we get:
//
// ._Query sequence for Step 1_:
// [source, cypher]
// ----
// FROM GRAPH ActorsFilmsCities AT 'graph://actors_films_cities...'
// MATCH (p:Person)-[:BORN_IN]->(c:City)
// INTO NEW GRAPH PersonCityEvents AT 'some-location'
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (p)-[:BORN_IN]->(c)
//
// // Discard all tabular data and cardinality
// WITH GRAPHS *
// ----
//
// At this stage, *PersonCityEvents* is given by:
//
// image::opencypher-PersonCity-graph.jpg[Graph,600,400]
//
// ==== Step 2
//
// The next stage in the pipeline is to add the events information from *Events* to *PersonCityEvents*.
//
// Firstly, the source graph is set to *Events*, for which we need to provide the physical address:
//
// [source, cypher]
// ----
// FROM GRAPH Events AT 'graph://events...'
// ----
//
// At this point, the *Events* graph is in scope.
//
// All the events information -- the event itself, its type, the year in which it occurred, and the city in which it took place -- is matched:
//
// [source, cypher]
// ----
// MATCH (c)<-[:IN_CITY]-(e)-[:IN_YEAR]->(y),
//       (e)-[:IS_A]->(et {value: 'Criminal Event'})
//
// // Do matches for all other event types: Public Event, War Event....
// ...
// ----
//
// The target graph is set to the *PersonCityEvents* graph (created earlier):
//
// [source, cypher]
// ----
// INTO GRAPH PersonCityEvents
// ----
//
// Using the results from the `MATCH` clause, create a subgraph with more intelligible semantics through the transformation of the events information into a less verbose form through greater use of node-level properties.
//  Write the subgraph to *PersonCityEvents*.
//
// [source, cypher]
// ----
// MERGE (c:City {name: c.value})
// MERGE (e {title: e.value, year: y.value})
// MERGE (e)-[:HAPPENED_IN]->(c)
// SET e :WarEvent
//
// // Do for all remaining event types
// ...
// ----
//
// Putting all these statements together, we get:
//
// ._Query sequence for Step 2_:
// [source, cypher]
// ----
// FROM GRAPH Events AT 'graph://events...'
// MATCH (c)<-[:IN_CITY]-(e)-[:IN_YEAR]->(y),
//       (e)-[:IS_A]->(et {value: 'Criminal Event'})
//
// // Do matches for all other event types: Public Event, War Event....
// ...
// INTO GRAPH PersonCityEvents
// MERGE (c:City {name: c.value})
// MERGE (e {title: e.value, year: y.value})
// MERGE (e)-[:HAPPENED_IN]->(c)
// SET e :WarEvent
//
// // Do for all remaining event types
// ...
//
// // Discard all tabular data and cardinality
// WITH GRAPHS *
// ----
//
// *PersonCityEvents* now contains the following data:
//
// image::opencypher-PersonCityEvents-graph.jpg[Graph,800,700]
//
// ==== Step 3
//
// The last step in the data integration pipeline is the creation of a new, temporary graph, *Temp-PersonCityCrimes*, which is to be populated with the subgraph of all the criminal events and associated nodes from *PersonCityEvents*.
//
// Set *PersonCityEvents* to be in scope:
//
// [source, cypher]
// ----
// FROM GRAPH PersonCityEvents
// ----
//
// Next, obtain the subgraph of all criminal events -- i.e. nodes labelled with `CriminalEvent` -- and their associated `City` nodes, and `Person` nodes associated with the `City` nodes:
//
// [source, cypher]
// ----
// MATCH (ce:CriminalEvent)-[:HAPPENED_IN]->(c:City)<-[:BORN_IN]-(p:Person)
// ----
//
// Create the new, temporary graph *Temp-PersonCityCrimes*, and set it as the target graph:
//
// [source, cypher]
// ----
// INTO NEW GRAPH Temp-PersonCityCrimes
// ----
//
// Write the subgraph acquired earlier to *Temp-PersonCityCrimes*.
//
// [source, cypher]
// ----
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (ce:CriminalEvent {title: ce.title, year: ce.year})
// MERGE (p)-[:BORN_IN]->(c)
// MERGE (ce)-[:HAPPENED_IN]->(c)
// ----
//
// Putting all these statements together, we get:
//
// ._Query sequence for Step 3_:
// [source, cypher]
// ----
// FROM PersonCityEvents
// MATCH (ce:CriminalEvent)-[:HAPPENED_IN]->(c:City)<-[:BORN_IN]-(p:Person)
// INTO NEW GRAPH Temp-PersonCityCrimes
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (ce:CriminalEvent {title: ce.title, year: ce.year})
// MERGE (p)-[:BORN_IN]->(c)
// MERGE (ce)-[:HAPPENED_IN]->(c)
//
// ----
//
// And, as the final step of the entire data integration pipeline, return *Temp-PersonCityCrimes*, which is comprised of the following data:
//
// image::opencypher-PersonCityCriminalEvents-graph.jpg[Graph,700,550]
//
// ._The full data integration query pipeline is given by_:
// [source, cypher]
// ----
// FROM GRAPH ActorsFilmsCities AT 'graph://actors_films_cities...'
// MATCH (p:Person)-[:BORN_IN]->(c:City)
// INTO NEW GRAPH PersonCityEvents AT 'some-location'
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (p)-[:BORN_IN]->(c)
//
// WITH GRAPHS *
//
// FROM GRAPH Events AT 'graph://events...'
// MATCH (c)<-[:IN_CITY]-(e)-[:IN_YEAR]->(y),
//       (e)-[:IS_A]->(et {value: 'Criminal Event'})
//
// // Do matches for all other event types: Public Event, War Event....
// ...
// INTO GRAPH PersonCityEvents
// MERGE (c:City {name: c.value})
// MERGE (e {title: e.value, year: y.value})
// MERGE (e)-[:HAPPENED_IN]->(c)
// SET e :WarEvent
//
// // Do for all remaining event types
// ...
//
// WITH GRAPHS *
//
// FROM GRAPH PersonCityEvents
// MATCH (ce:CriminalEvent)-[:HAPPENED_IN]->(c:City)<-[:BORN_IN]-(p:Person)
// INTO NEW GRAPH Temp-PersonCityCrimes
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (ce:CriminalEvent {title: ce.title, year: ce.year})
// MERGE (p)-[:BORN_IN]->(c)
// MERGE (ce)-[:HAPPENED_IN]->(c)
//
// RETURN GRAPHS Temp-PersonCityCrimes
// ----
//
// [[data-aggregation-example]]
// === Using a pipeline to perform aggregations and return tabular data and graphs
//
// This example shows how to aggregate detailed sales data within a graph -- in effect, performing a 'roll-up' -- in order to obtain a high-level summarized view of the data, stored and returned in another graph, as well as returning an even higher-level view as an executive report.
// The summarized graph may be used to draw further high-level reports, but may also be used to undertake 'drill-down' actions by probing into the graph to extract more detailed information.
//
// Assume we have the graph *SalesDetail*, representing the sale of products in stores across various regions:
//
// image::opencypher-SalesDetail-graph.jpg[Graph,800,700]
//
// This models the following entities:
//
// * Regions may have many stores.
// * Stores:
// ** A store is identified by a unique `code`.
// ** A store is contained in exactly one region.
// ** A store may have multiple orders.
// * Products:
// ** A product is identified by a unique `code`.
// ** A product has a `RRP` property (Recommended Retail Price).
// ** A product may appear in one or more orders as a product _item_.
// * Sales orders:
// ** An order is identified by a unique order number, given by `num`.
// ** The `YYYYMM` property represents the year and month portion of the date of the order.
// ** An order is associated with exactly one store and contains one or more product items, representing the fact that the product item was sold in the store and is a part of the order.
// ** The relationship of between an order and a product contains the following properties:
// *** `soldPrice`: the price at which the product item was actually sold (usually lower than the product's RRP).
// *** `numItemsSold`: the number of the actual product items sold in the order.
//
// The following pipeline will create a summarized view of this data, and store it in a new summary graph called *SalesSummary*.
//
// We begin by referencing the *SalesDetail* graph, and matching on all products in all orders for all stores in all regions.
//
// [source, cypher]
// ----
// FROM GRAPH SalesDetail AT ‘graph://...’
// MATCH (p:Product)-[r:IN]->(o:Order)<-[HAS]-(s:Store)-[:IN]->(reg:Region)
// ----
//
// We aggregate the (tabular) data across all orders in order to obtain the total sales amount grouped by the product, store and region, and alias this value as `storeProductTotal`.
// As this tabular data is required to populate the summary graph later on, we pass it further down the pipeline:
//
// [source, cypher]
// ----
// WITH reg.name AS regionName,
//      s.code AS storeCode,
//      p.code AS productCode,
//      sum(r.soldPrice * r.numItemsSold) AS storeProductTotal
// ----
//
// The tabular data consists of the following:
//
// [source, cypher]
// ----
// +------------+-----------+-------------+-------------------+
// | regionName | storeCode | productCode | storeProductTotal |
// +------------+-----------+-------------+-------------------+
// | APAC       | AC-888    | PEN-1       | 20.00             |
// | APAC       | AC-888    | TOY-1       | 45.00             |
// | EMEA       | LK-709    | BOOK-2      | 10.00             |
// | EMEA       | LK-709    | TOY-1       | 40.00             |
// | EMEA       | LK-709    | BOOK-5      | 15.00             |
// | EMEA       | WW-531    | BOOK-5      | 18.00             |
// | EMEA       | WW-531    | BULB-2      | 190.00            |
// | EMEA       | WW-531    | PC-1        | 440.00            |
// +------------+-----------+-------------+-------------------+
// 8 rows
// ----
//
// Next, we read from the *SalesDetail* graph to get the store, product and region information:
//
// [source, cypher]
// ----
// MATCH (p:Product)-[:IN]->(o:Order)<-[:HAS]-(s:Store)-[:IN]->(r:Region)
// ----
//
// We now create a new graph, *SalesSummary*, containing the summarized view of the sales information across regions, products and stores:
//
// [source, cypher]
// ----
// INTO NEW GRAPH SalesSummary
// MERGE (s:Store {storeCode: s.code})
// MERGE (r:Region {name: r.name})
// MERGE (p:Product {productCode: p.code, RRP: p.RRP})
// MERGE (s)-[:IN]->(r)
// MERGE (p)-[:SOLD_IN]->(s)
//
// // Get the total amount sold for a store
// WITH storeCode, sum(storeProductTotal) AS totalSales
// // Get the total amount sold for a product
// WITH productCode, sum(storeProductTotal) AS soldTotal
//
// // Update all store nodes with the new totalSales property
// MATCH (s:Store)
// SET s.totalSales = totalSales
// WHERE s.code = storeCode
//
// // Update all product nodes with the new soldTotal property
// MATCH (p:Product)
// SET p.soldTotal = soldTotal
// WHERE p.code = productCode
//
// // Update all (:Product)-[SOLD_IN]->(:Store) relationships with the new sold property
// MATCH (p:Product)-[r:SOLD_IN]->(s:Store)
// SET r.sold = storeProductTotal
// WHERE p.code = productCode
// AND s.code = storeCode
// ----
//
// As a final step, the *SalesSummary* graph is returned, along with a high-level summarized tabular view of store sales data.
//
// [source, cypher]
// ----
// RETURN regionName,
//        storeCode,
//        sum(storeProductTotal) AS totalStoreSales
// GRAPH SalesSummary
// ----
//
// The *SalesSummary* graph is comprised of the following:
//
// image::opencypher-SalesSummary-graph.jpg[Graph,800,700]
//
// The high-level summarized tabular data consists of the following:
//
// [source, cypher]
// ----
// +------------+-----------+-----------------+
// | regionName | storeCode | totalStoreSales |
// +------------+-----------+-----------------+
// | APAC       | AC-888    | 65.00           |
// | EMEA       | LK-709    | 65.00           |
// | EMEA       | WW-531    | 648.00          |
// +------------+-----------+-----------------+
// 3 rows
// ----
//
// We note that the *SalesSummary* graph can be used to generate further high-level sales summaries, such as the total sales of a particular product (shown <<data-aggregation-external-example, here>>), as well as more detailed views.
//
// ._The full aggregation query pipeline is given by_:
// [source, cypher]
// ----
// FROM GRAPH SalesDetail AT ‘graph://...’
// MATCH (p:Product)-[r:IN]->(o:Order)<-[HAS]-(s:Store)-[:IN]->(reg:Region)
//
// WITH reg.name AS regionName,
//      s.code AS storeCode,
//      p.code AS productCode,
//      sum(r.soldPrice * r.numItemsSold) AS storeProductTotal
//
// MATCH (p:Product)-[:IN]->(o:Order)<-[:HAS]-(s:Store)-[:IN]->(r:Region)
//
// INTO NEW GRAPH SalesSummary
// MERGE (s:Store {code: s.code})
// MERGE (r:Region {name: r.name})
// MERGE (p:Product {code: p.code, RRP: p.RRP})
// MERGE (s)-[:IN]->(r)
// MERGE (p)-[:SOLD_IN]->(s)
//
// // Get the total amount sold for a store
// WITH storeCode, sum(storeProductTotal) AS totalSales
// //Get the total amount sold for a product
// WITH productCode, sum(storeProductTotal) AS soldTotal
//
// // Update all store nodes with the new totalSales property
// MATCH (s:Store)
// SET s.totalSales = totalSales
// WHERE s.code = storeCode
//
// // Update all product nodes with the new soldTotal property
// MATCH (p:Product)
// SET p.soldTotal = soldTotal
// WHERE p.code = productCode
//
// // Update all (:Product)-[SOLD_IN]->(:Store) relationships with the new sold property
// MATCH (p:Product)-[r:SOLD_IN]->(s:Store)
// SET r.sold = storeProductTotal
// WHERE p.code = productCode
// AND s.code = storeCode
//
// RETURN regionName,
//        storeCode,
//        sum(storeProductTotal) AS totalStoreSales
// GRAPH SalesSummary
// ----
//
// [[data-aggregation-external-example]]
// === Using a pipeline in an external execution context
//
// We show how a pipeline may be used in an external execution context; i.e. where processes external to the pipeline -- for example, an SQL query engine invoking a Cypher query as a graph function, or an automated business workflow system -- can be used to orchestrate externally query composition within the pipeline.
//
// Assume that the pipeline defined <<data-aggregation-example, above>> has executed and produced the *SalesSummary* graph, and that there is in scope a table, populated by some external process, containing the following list of codes (given by 'product_code') of the products of interest:
//
// [source, cypher]
// ----
// TOY -1
// BOOK-5
// BULB-2
// ----
//
// We obtain the graph and the table:
//
// [source, cypher]
// ----
// WITH product_code AS productCode GRAPH SalesSummary
// FROM GRAPH SalesSummary
// ----
//
// We then match the products in the *SalesSummary* graph with the ones from the input table, and produce a high-level report on the sales by product for only those products:
//
// [source, cypher]
// ----
// MATCH (p:Product)
// WHERE p.code = productCode
// RETURN p.code AS productCode, p.soldTotal AS totalProductSales
// ----
//
// The resulting 'sales by product' report contains:
//
// [source, cypher]
// ----
// +-------------+-------------------+
// | productCode | totalProductSales |
// +-------------+-------------------+
// | TOY-1       | 85.00             |
// | BOOK-5      | 33.00             |
// | BULB-2      | 190.00            |
// +-------------+-------------------+
// 3 rows
// ----
//
== Interaction with existing features

This proposal is far reaching as it changes both the property graph model and the execution model of the language.

However, the change has been carefully designed to not change the semantics of existing queries.

== Alternatives

The scope of this CIP could be reduced by not separating between the source and target graph.

== What others do

SPARQL only provides basic facilities for returning graphs using `CONSTRUCT`.

Neither Gremlin nor PGQL have developed facilities for the direct construction and manipulation of graphs.

== Benefits to this proposal

Cypher is evolved to become a query language that is properly closed under graphs.

== Caveats to this proposal

This is a fundamental and large change to the language whose long-term consequences are difficult to assess.
