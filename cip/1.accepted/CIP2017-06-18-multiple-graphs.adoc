= CIP2017-06-18 Multiple Graphs
:numbered:
:toc:
:toc-placement: macro
:source-highlighter: codemirror

*Author:* Stefan Plantikow <stefan.plantikow@neotechnology.com>

This material is based on internal contributions of Alastair Green <alastair.green@neotechnology.com>, Mats Rydberg <mats.rydberg@neotechnology.com>, Martin Junghanns <martin.junghanns@neotechnology.com>, Tobias Lindaaker <tobias.lindaaker@neotechnology.com>, Petra Selmer <petra.selmer@neotechnology.com>

[abstract]
.Abstract
--
// This CIP proposes extending Cypher to support the construction, transformation, and querying of multiple graphs by adopting (i) the proposed multiple property graphs model, (ii) the proposed multiple graphs execution model, and (iii) by introducing new syntax for working with multiple graphs.
--

toc::[]



== Motivation

Cypher today is a query language for property graphs that provides access to a single, global, implicit graph in order to extract, transform, and return tabular data that is derived from it.
While such returned tabular data may include graph entities (such as nodes and relationships), in essence Cypher as a language is not closed under graphs and as a consequence, Cypher queries are not yet (graph) compositional.

However it seems desirable that a language for property graphs should not only enable querying and updating a selected graph but should also support the construction and transformation of multiple graphs, ideally by utilizing a mechanism for incremental query composition.

Furthermore, adding support for working with multiple graphs has recently been identified as a frequently requested feature:

* It enables the dynamic construction of graph views (e.g. for access control)
* It allows reasoning over multiple versions of the same graph (e.g. comparing daily snapshots)
* It provides an effective grouping mechanism for naturally-partitioned data (e.g. per-continent graph)
* It is useful for combining data from disparate data sources in one system (e.g. in federation and data integration scenarios)
* It fits the paradigm of prominent analytical big-data processing systems (e.g. Apache Spark)
* It mirrors mathematical graph theory where working with multiple graphs is common



== Multiple property graphs model

The data model used here is called the *multiple property graphs data model*.
It extends the original https://github.com/opencypher/openCypher/blob/master/docs/property-graph-model.adoc[*property graph model*] with the notion of multiple graphs as outlined in the following subsections.


=== Model instance

_Definition_: A *multiple property graphs model instance* is a set of zero or more property graphs.


=== Definitions

_Definition_: The constituents of a multiple property graphs model instance are called its *model elements*.
This includes property graphs, nodes, and relationships.

_Definition_: An *identity* is a value that is used to identify individual model elements and to distinguish between multiple model elements from a set of model elements in a given scope.

_Definition_: The constituents of a model element (including its identity) are called its *content*.

_Definition_: A *label* is a symbolic string that is used for classifying nodes.

_Definition_: A *relationship type* is a symbolic string that is used for classifying relationships.

_Definition_: A *property* is a tuple consisting of a named *property key* and a *property value*.

_Definition_: A *(property) graph* has a *graph identity* which is an identity that uniquely identifies the graph such that it is able to be distinguished from other graphs in the same multiple property graph model instance.
A property graph further consists of a set of nodes and a set of relationships that connect the nodes of the property graph.
Each property graph is contained in exactly one multiple property graphs model instance.

Graphs may be either immutable or mutable.
This information is not considered to be part of the content of the graph.

_Definition_: A *node* has a *node identity* which is an identity that uniquely identifies the graph such that it is able to be distinguished from other nodes that are contained in the same property graph.
A node further consists of a set of zero or more labels and zero or more properties with mutually different property keys.
Each node is contained in exactly one property graph.

_Definition_: A *relationship* has a *relationship identity* which is an identity that uniquely identifies the graph such that it is able to be distinguished from other relationships that are contained in the same property graph.
A relationship further consists of a *start node*, an *end node*, and exactly one relationship type, and zero or more properties with mutually different property keys.
Each relationship is contained in exactly one property graph and its start node and its end node are both contained in the same property graph as the relationship.

_Definition_: Both nodes and relationships are called *entities*.

_Definition_: Both node and relationship identities are called *entity identities*.


=== Valid model instance

_Definition_: The set of *atoms* of an arbitrary value `v` (named `atoms(v)`) is defined as follows:

 * If `v` is a scalar value, `atoms(v) = {v}`
 * If `v` is a list value `[e~1~, e~2~, ..., e~n~]`, `atoms(v) = {v} UNION atoms(e~1~) UNION atoms(e~2~) UNION ... UNION atoms(e~n~)`
 * If `v` is a map or a node or a relationship with `values(v)`, `atoms(v) = {v} UNION atoms(values(v))`
 * Nothing else

_Definition_: A *valid multiple property graphs model instance* adheres to the following restrictions:

 * The set of atoms of an identity of any model element must not contain `NULL`.
 * The set of atoms of an identity of any model element must not contain a model element.
 * Property values must not be `NULL`.
   (Note that this differs from an entity not having a property key)
 * The set of atoms of any property value of any entity must not contain a model element.


=== Functions for identity reflection

The identities of model elements may be obtained using the following functions:

The `graph(e)` function returns the *graph identity* of the graph that contains an entity `e`.

The `id(n)` function returns the *node identity* of a node `n`.

The `id(r)` function returns the *relationship identity* of a relationship `r`.



== Statements

_Definition_: A *source program* is a piece of text.

It is intended to be both a syntactically valid term according to the root production rule of the grammar of the Cypher property graph query language and also a semantically valid term according to the semantic rules of the Cypher property graph query language.

_Definition_: A *statement* is a source program that is a syntactically valid term according to the root production rule of the grammar of the Cypher property graph query language.

_Definition_: A *valid statement* is a statement that is valid according to the semantic rules of the Cypher property graph query language.

Statements in turn consist of a chain of one or more clauses which each may be further qualified by clause arguments, sub-clauses and sub-clause arguments.

_Definition_: Clauses may be classified according to their side-effects as either

 * *reading clauses* that read data
 * *updating clauses* that read and update data
 * *schema clauses* that only read from and update the schema

// A statement may either be a *single statement* or a *statement chain*.

_Definition_: A _statement_ may be categorized as:

 * A *reading query* is a statement consisting of reading clauses that reads and returns data
 * An *updating query* is a statement consisting of reading and updating clauses that reads, updates and returns data
 * An *updating command* is a statement consisting of reading and updating clauses that reads and updates data but returns no data
 * A *schema command* is a statement consisting of schema clauses that only updates the schema


// TODO
// _Definition_: A _statement chain_ is a single statement followed by a semicolon followed by another statement.

== Query processing

_Definition_: A *query processor* is a query processing service that executes a source program on behalf of a *client* and provides the client with the *execution result* that describes the outcome of executing the source program.
A query processor maintains exactly one _multiple property graphs model instance_.
A query processor maintains exactly one _catalog_.


=== Catalog

// TODO: graph references
_Definition_: A _catalog_ is a mapping from *fully qualified graph names* to graph references.
Multiple entries in the catalog may refer to the same graph.

A fully qualified graph name should use the syntax for dotted variable identifiers and consists of an optional *graph namespace*, and a mandatory *graph name*.

Note:: In practice, a query processor might have a catalog shared by all users, or provide a different catalog for each user.
This is not considered here based on the simplifying assumption that all client requests are made by the same user.


=== Execution of client requests


==== Definitions

_Definition_: A source program together with all required parameters is called a *client request*.

_Definition_: The result of executing a client request is called an *execution result*.
An execution result is one of

* a *tabular result*; i.e. a collection of records where each record has the exact same set of named fields.
Tabular results may contain duplicate results and may optionally be ordered
* a *graph result*; i.e. the contents of a graph as described by its set of nodes and relationships
* an *execution error*; i.e. a message describing the reason that prevented the query processor from executing the client request correctly

_Definition_: An *empty result* is a tabular result containing one record with no fields.


==== Request execution

Clients interact with the query processor by submitting a client request.
The source program is then executed by the query processor and an execution result is returned to the client for consumption.

_Definition_: *Raising an error* refers to aborting the execution of a currently-executing client request and returning the error as the final execution result of the client request back to the client.

An execution error is raised if the client request does not contain a semantically valid statement.


// ==== Execution of statement chains
//
// Statement chains are executed by executing all contained single statements in the order given.
// If execution of any contained single statement fails with an error, the execution of the whole statement fails with the same error.
// Otherwise, the query processor discards all intermediary results produced by a statement chain and only returns the execution result for the last single statement.


==== Identity validity during execution

Identities are only guaranteed to be valid for the duration of executing a statement and consuming its result.

Implementations may choose to guarantee the validity of identities across multiple client requests.

Note:: As a consequence, the same identity value may refer to different model elements in results returned by different client requests.


==== Returning graph model elements

If an execution result that is returned _to the client_ contains a model element, this model element is returned together with its content at the time of terminating the query (i.e. the client always receives the current content of all model elements).

Note:: Additionally, a result may contain implementation specific metadata such as a summary of performed update activity (e.g. the number of nodes created) or a detailed query plan.


=== Working graph

// TODO: unset
Most Cypher clauses operate within the context of a *working graph*, by reading or updating it.

_Definition_: The _working graph_ is a graph reference that is maintained during statement execution.
The working graph is optional and may be unset at the start of executing a statement.

The working graph may either reference a graph in the catalog or a graph that was dynamically constructed during statement execution.

A query processor may choose to establish an *initial working graph* for each executed statement.
The details of this are left to implementations.

If a query processor has not established an initial working graph (i.e. the working graph is unset) and the statement fails to set a working graph explicitly before attempting to operate on the working graph, an error is raised.



== Graph operations in queries

The working graph may be operated on in the following ways:

* The working graph can be changed by selecting a graph that is known by the catalog
* The working graph is implicitly used during pattern matching and creational activity
* The working graph may be returned as a query result
* The working graph can be changed by constructing a new graph
* The working graph can be changed by constructing a common graph union
* The working graph can be changed by constructing a disjoint graph union
* The working graph can be kept while the binding table is discarded
* The graph identity of the working graph may be obtained using a reflective function


=== Selecting the working graph from the catalog for querying

// TODO: Asciidoc circle references
// TODO: Asciidoc line numbers
The working graph may be changed for all subsequent querying clauses using two forms:

[source, cypher]
----
[1] FROM < graph-name >
[2] FROM GRAPH
----

`<graph-name>` is expected to be the name of a graph in the catalog.
If `<graph-name>` is not the name of a graph in the catalog, an error is raised.
It is an error to perform an updating operation on a working graph that was introduced using `FROM [GRAPH]`.

Additionally, `FROM GRAPH` may be used to select the working graph for further read-only operations.


=== Selecting the working graph from the catalog for updating

The working graph may be changed for all subsequent querying and updating clauses using two forms:

[source, cypher]
----
[1] UPDATE < graph-name >
[2] UPDATE GRAPH
----

`<graph-name>` is expected to be the name of a graph in the catalog.
If `<graph-name>` is not the name of a graph in the catalog, an error is raised.
It is an error to not perform at least a single updating operation on a working graph that was introduced using `UPDATE [GRAPH]`.

Additionally, `UPDATE GRAPH` may be used to select the working graph for further updating operations.


=== Using the working graph when interpreting a pattern

All bound entities are matched against the working graph in both pattern matching and updating commands.
// TODO: Should this be an error instead?
If one of the bound variables in a pattern is an entity that is not contained in the working graph, the whole pattern does not match.

An error is raised, if a statement attempts to update an entity that is not contained in the working graph.

==== Copy patterns

A new type of pattern that is called a *copy pattern* may be used to copy all labels and properties of a node or the relationship type and all properties of a relationship.
The syntax of clone patterns is:

[source, cypher]
----
MATCH (a)-[r]->(b)
FROM another_graph
MATCH (x COPY OF b)-[COPY OF r]->()
...
----

Copying relationships ignores the start and the end node of the relationship.

Copy patterns may be used in updating statements.

==== Clone patterns

A new type of pattern that is called a *clone pattern* may be used find the clone (if present) for a source entity as determined by provenance tracking.

[source, cypher]
----
MATCH (a)-[r]->(b)
FROM another_graph
MATCH (x CLONE OF b)-[CLONE OF r]->()
...
----

Clone patterns should not be used in updating statements.


=== Returning a graph result

The working graph may be returned as an execution result using:

[source, cypher]
----
RETURN GRAPH
----

Additionally, the following syntactic form is supported for selecting the working graph from the catalog and returning it at the same time:

[source, cypher]
----
RETURN GRAPH < graph-name >
----

Graphs are always returned by reference during execution inside the query processor.
This does not affect the rules on returning model elements together with their content to the client which ensure that a graph result will be returned by value to the client.


=== Constructing a graph

*Graph construction* dynamically constructs a new working graph in order to query it, update it, store it in the catalog, or return it to the client.

Graph construction is the dual operation to graph matching: While graph matching extracts pattern instances into variable bindings from the working graph, graph construction builds a new working graph from variable bindings.

All nodes and relationships in the newly constructed graph have new entity identities and are different from any previously matched entities.

The basic form of graph construction is:

[source, ebnf]
----
< graph-construction > :=
  < construct-clause >
  < update-command >*
  [WITH ... | WITH GRAPH | RETURN ... | RETURN GRAPH ]
  ;

< construct-clause > :=
  CONSTRUCT
    [ON GRAPH]
    [ON < graph-name-list > ]
    [CLONE < clone-item-list > | '*']
  ;

< graph-name-list > := < graph-name > [ ',' < graph-name > ]* ;

< clone-item-list := < clone-item > [ ',' < clone-item > ]*
< clone-item > :=
  ( < expr > [AS < alias >] | < variable > ) ;
----

Graph construction supports sub-clauses for the *cloning of existing graphs* and the *cloning of existing entities*.

A single statement may end in a `<graph-construction>`.


==== Cloning

// TODO: FORK nodes
// TODO: REMOVE n.prop on clokes
In order to reconstruct subgraph structures from other graphs in the new graph, `CONSTRUCT` supports the addition of *cloned entities* in the new graph.

_Definition_: *Cloning* ensures that exactly one new entity (called a *clone*) is created in the new graph for a given cloned entity (called its *source*) from a source graph.
If the same source is cloned multiple times this will still only create one clone in the new graph.
Every clone has exactly the same labels or relationship type as well as the same properties as the source (i.e. a clone can be seen as a "representative" of the source in the new graph).
Cloning a relationship implicitly clones its start node and its end node and uses these clones as the start node and the end node of the relationship clone.

_Definition_: It is possible to clone an entity over multiple steps of graph construction.
In that case, if multiple entities are cloned into the same graph that in turn are both clones of a shared source,
only one entity is constructed for these entities.
This is called *provenance tracking*.

The `ON GRAPH` sub-clause may be used to clone all nodes and relationships from the working graph into the new graph.

The `ON < graph-name-list >` sub-clause may be used to clone all nodes and relationships from the given graphs in the catalog into the new graph.

The `CLONE < clone-item-list >` sub-clause may be used to clone entities and bind the cloned entities to new variable names or shadow already bound variables.
Additionally, the `CLONE *` sub-clause may be used to clone all variables that are visible in the current scope.
`CLONE` constructs cloned entities for each input record subject to the following rules:

 * Cloning a single, already bound variable rebinds the variable. In other words `CLONE a` is interpreted as `CLONE a AS a`.
 No other form of `CLONE` may rebind an already bound variable
 * Cloning a nested value (like a path) implicitly clones all contained nodes and relationships


==== Building constructed graphs

Constructed graphs are built by explicitly populating them with entities using the following clauses:

 * `CREATE`
 * `MERGE`
 * `SET`
 * `REMOVE`
 * `[DETACH] DELETE`

An error is raised for any attempt to `SET` or `REMOVE` labels or properties of cloned entities during graph construction.


==== Updating constructed graphs

// TODO: Advanced conformance
Constructed graphs may be updated as well.

Updating relies on information from provenance tracking of cloned nodes in order to propagate updates to base data.

Constructed graphs may only be updated by

 * setting and removing properties
 * setting and removing labels
// TODO: * deleting nodes and relationships

An error is raised if an update to a constructed graph leads to a constraint violation in a source graph.


=== Graph union

The *common graph union* of two graphs may be computed using the following syntax:

[source, cypher]
----
< query-1 >
RETURN GRAPH
UNION
< query-2 >
RETURN GRAPH
----

The resulting union graph consists of clones of all entities from the two input graphs.

Note:: If a clone of the same source node is contained in both graphs, only one clone for that node is added to the result graph.


=== Disjoint graph union

The *disjoint graph union* of two graphs may be computed using the following syntax:

[source, cypher]
----
< query-1 >
RETURN GRAPH
UNION ALL
< query-2 >
RETURN GRAPH
----

The resulting union graph consists of copies of all entities from the two input graphs.

Note:: If a clone of the same source node is contained in both graphs, still two copies of that node are added to the result graph.


=== Discarding the binding table

The current binding table may be discarded while retaining the working graph using the following syntax:

[source, cypher]
----
WITH GRAPH
...
----

The remainder of the query after `WITH GRAPH` continues to operate on the same working graph but using an empty binding table (no fields, single record).


=== Function for determining the working graph identity

The `graph()` function returns the *graph identity* of the working graph.



== Creating and administrating graphs in the catalog


=== Creating empty graphs

Creating a new, empty graph in the catalog is done using the new catalog command `CREATE GRAPH <graph-name>`.
If `<graph-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Creating new graphs and populating them from a query

`CREATE GRAPH <graph-name>` may be optionally followed by a subquery that returns a graph.
In that case, a new graph `<graph-name>` is created in the catalog for the graph returned by the subquery.
All entities in the new graph are considered to be copies of the entities in the returned graph (i.e. they are unrelated from the entities in the graph returned by the subquery in terms of provenance).
If `<graph-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Delete graph

The catalog command `DELETE GRAPH <graph-name>` deletes the graph with the name `<graph-name>` from the catalog.
If `<graph-name>` is not the name of a graph that already exists in the catalog, an error is raised.


=== Copy graph

The catalog command `COPY <old-name> TO <new-name>` copies the content and the schema of the graph with the name `<old-name>` in the catalog to a new graph with the name `<new-name>` in the catalog.
If `<old-name>` is not the name of a graph that already exists in the catalog, an error is raised.
If `<new-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Rename graph

The catalog command  `RENAME <old-name> TO <new-name>` removes the graph with the name `<old-name>` from the catalog and adds it as a new graph with the name `<new-name>` in the catalog.
If `<old-name>` is not the name of a graph that already exists in the catalog, an error is raised.
If `<new-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Truncating graphs

The catalog command `TRUNCATE <graph-name>` truncates the graph with the name `<graph-name` in the catalog.

Truncating a graph deletes all its nodes and relationships but retains any additional schema information like constraints.


== Determining the name of a graph

The `catalog(g)` function returns the catalog name for the graph identity `g` or `NULL` if `g` is a dynamically constructed graph.

The `catalog()` function returns the catalog name for the working graph or `NULL` if the working graph is a dynamically constructed graph.



== Examples

The following examples are intended to show how multiple graphs may be used, and focus on syntax.
We show two fully worked-through examples <<data-integration-example, here>> and <<data-aggregation-example, here>>, describing and illustrating every step of the pipeline in detail.

=== Creating and returning a new graph: a simple example

This query returns a graph containing all the people living in Berling in the `persons` graph and their `KNOWS` relationships.

[source, cypher]
----
FROM persons
MATCH (a:Person {city: "Berlin"})-[r:KNOWS]->(b:Person {city: "Berlin"})
CONSTRUCT
  CLONE a, b, r
RETURN GRAPH
----

By specifying the same predicate "{city: "Berlin"}" on both nodes, we are saying we are only interested in the graph of people in Berlin.

Another query we might want to do is to see all the people that live in Berlin, and also include all their known nodes, no matter where they live.

[source, cypher]
----
FROM persons
MATCH (a:Person {city: "Berlin"})-[r:KNOWS]-(b:Person)
CONSTRUCT
  CLONE a, b, r
RETURN GRAPH
----

=== Creating a new graph, switching contexts and returning a graph

[source, cypher]
----
FROM social-network
// .. and match some data
MATCH (a:Person)-[:KNOWS]->(b:Person)-[:KNOWS]->(c:Person) WHERE NOT (a)--(c)
CONSTRUCT
	CLONE a, c
	NEW (a)-[:POSSIBLE_FRIEND]->(c)
// All cardinality and bindings are removed here
MATCH (a:Person)-[e:POSSIBLE_FRIEND]->(b:Person)
// Return tabular and graph output
RETURN a.name, b.name, count(e) AS cnt
  ORDER BY cnt DESC
----


[[data-integration-example]]
=== A complete example illustrating a data integration scenario

Assume we have two graphs, *ActorsFilmsCities* and *Events*.
This example will show how these two graphs can be integrated into a single graph.

The *ActorsFilmsCities* graph models the following entities:

* Actors and people fulfilling other roles in the film-industry.
* Films in which they acted, or directed, or for which they wrote the soundtrack.
* Cities in which they were born.
* The relationships between family members and colleagues.

Each node is labelled and contains one or two properties (where `YOB` stands for 'year of birth'), and each relationship of type `ACTED_IN` has a `characterName` property indicating the name of the character the relevant `Actor` played in the `Film`.

image::opencypher-PersonActorCityFilm-graph.jpg[Graph,800,650]

The other graph, *Events*, models information on events.
Each event is linked to an event type by an `IS_A` relationship, to a year by an `IN_YEAR` relationship, and to a city by an `IN_CITY` relationship.
For example, the _Battle of Britain_ event is classified as a _War Event_, occurred in the year _1940_, and took place in _London_.

In contrast to the *ActorsFilmsCities* graph, *Events* contains no labels on any node, no properties on any relationship, and only a single `value` property on each node.
*Events* can be considered to be a snapshot of data from an RDF graph, in the sense that every node has one and only one value; i.e. in contrast to a property graph, an RDF graph has properties on neither nodes nor relationships.
(For easier visibility, we have coloured accordingly the cities and city-related relationships, event types and event-type relationships, and year and year-related relationships.)

image::opencypher-Events-graph.jpg[Graph,800,600]

The aims of the data integration exercise are twofold:

* Create and persist to disk (for future use) a new graph, *PersonCityEvents*, containing an amalgamation of data from *ActorsFilmsCities* and *Events*.
*PersonCityEvents* must contain all the event information from *Events*, and only `Person` nodes connected to `City` nodes from *ActorsFilmsCities*.

* Return a graph containing a subset of the data from *PersonCityEvents*, consisting only of the criminal events, their associated `City` nodes, and `Person` nodes associated with the `City` nodes.

==== Step 1

The very first step is to create the graph in the catalog:

[source, cypher]
----
CREATE GRAPH PersonCityEvents
----

This creates an empty graph in the catalog named `PersonCityEvents`.


===== Step 2

The next step is to copy over persons and cities from `ActorsFilmsCities`.

[source, cypher]
----
[0] FROM ActorsFilmsCities
[1] MATCH (p1:Person)-[:BORN_IN]->(c1:City)
[2] UPDATE PersonCityEvents
[3] MERGE (p2:Person {name: p1.name, YOB: p1.YOB})
[4] MERGE (c2:City {name: c1.name})
[5] MERGE (p2)-[:BORN_IN]->(c2)
----

Here, we are first setting the working graph to the ActorsFilmsCities [0], and then we are matching on this graph [1].
That is all the input data we need, so we can now switch over to the output graph [2] and create nodes and relationships in it [3-5]. TODO Maybe talk about that we could have used CONSTRUCT instead.

At this stage, *PersonCityEvents* is given by:

image::opencypher-PersonCity-graph.jpg[Graph,600,400]

==== Step 3

The next stage in the pipeline is to add the events information from *Events* to *PersonCityEvents*.

[source, cypher]
----
[ 0] FROM Events
[ 1] MATCH (c)<-[:IN_CITY]-(e)-[:IN_YEAR]->(y),
[ 2]      (e)-[:IS_A]->(et)
[ 3] WITH *, CASE et.value
[ 4]	  WHEN 'Criminal Event' THEN 'criminal'
[ 5]	  WHEN 'Public Event' THEN 'public'
[ 6]	  WHEN 'War Event' THEN 'war'
[ 7]	  WHEN 'Royal Event' THEN 'royal'
[ 8]	END as eventType
[ 9] UPDATE PersonCityEvents
[10] MERGE (c:City {name: c.value})
[11] MERGE (e:Event {title: e.value, year: y.value, type: eventType})
----

First, we specify that we start reading from the Events graph [0].
All the events information -- the event itself, its type, the year in which it occurred, and the city in which it took place -- is matched [1-2].

Next, we create a string value for the type of event, and store it in the variable `eventType`[3-8]

The target graph is set to the *PersonCityEvents* graph [9].

Using the results from the `MATCH` clause, we create a subgraph with more intelligible semantics through the transformation of the events information into a less verbose form through greater use of node-level properties.


*PersonCityEvents* now contains the following data:

image::opencypher-PersonCityEvents-graph.jpg[Graph,800,700]

==== Step 4

The last step in the data integration pipeline is to return part of the newly created graph - only the criminal events and related information is returned from *PersonCityEvents*.

[source, cypher]
----
[0] FROM PersonCityEvents
[1] MATCH
[2]  (ce:Event {type:'criminal'}),
[3]  (ce)-[h:HAPPENED_IN]->(c:City)<-[b:BORN_IN]-(p:Person)
[4] CONSTRUCT
[5]   CLONE p, c, ce, h, b
[6] RETURN GRAPH
----

Again, we start from `PersonCityEvents` [0].

Next, obtain the subgraph of all criminal events -- i.e. nodes labelled with `Event` of type "criminal" [2] -- and their associated `City` nodes, and `Person` nodes associated with the `City` nodes [3].

And, as the final step of the entire data integration pipeline, return *Temp-PersonCityCrimes*, which is comprised of the following data:

This is the final step of the entire data integration pipeline, we return this graph [6].

image::opencypher-PersonCityCriminalEvents-graph.jpg[Graph,700,550]

// ._The full data integration query pipeline is given by_:


//
// === Using a pipeline of temporary graphs to process and return a subgraph
//
// [source, cypher]
// ----
// // Set scope to the whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data.
// MATCH (a:Person)-[:IS_LOCATED_IN]->(c:City),
//       (c)->[:IS_LOCATED_IN]->(co:Country),
//       (a)-[e:KNOWS]-(b)
//
// // Create a new temporary named graph,
// INTO NEW GRAPH sn_updated
// // add previous matches to new graph,
// CREATE (a)-[e]-(b)
// // update existing nodes.
// SET a.country = cn.name
// // ... and finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// FROM GRAPH sn_updated
// MATCH (a:Person)-[e:KNOWS]->(b:Person)
// WITH a.country AS a_country, b.country AS b_country, count(a) AS a_cnt, count(b) AS b_cnt, count(e) AS e_cnt
// INTO NEW GRAPH rollup
// MERGE (:Persons {country: a_country, cnt: a_cnt})-[:KNOW {cnt: e_cnt}]->(:Persons {country: b_country, cnt: b_cnt})
//
// // Return final graph output
// RETURN GRAPH rollup
// ----
//
// === A more complex pipeline: using and persisting multiple graphs
//
// [source, cypher]
// ----
// // Set scope to the whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data.
// MATCH (a:Person)-[e]->(b:Person),
//       (a)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c:Country {name: ‘Sweden’}),
//       (b)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c)
// // Create a persistent graph at 'graph://social-network/swe'
// INTO NEW GRAPH sweden_people AT './swe'
// // connecting persons that live in the same city in Sweden.
// CREATE (a)-[e]->(b)
//
// // Finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// MATCH (a:Person)-[e]->(b:Person),
//       (a)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c:Country {name: ‘Germany’}),
//       (b)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c)
// // Create a persistent graph at 'graph://social-network/ger'
// INTO NEW GRAPH german_people AT './ger'
// // connecting persons that live in the same city in Germany.
// CREATE (a)-[e]->(b)
//
// // Finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// // Start query on the 'sweden_people' graph
// FROM GRAPH sweden_people
// MATCH p=(a)--(b)--(c)--(a) WHERE NOT (a)--(c)
// // Create a temporary graph 'swedish_triangles'
// INTO NEW GRAPH swedish_triangles
// MERGE p
//
// // and return it together with a count of its content
// RETURN count(p) AS num_triangles GRAPHS swedish_triangles, sweden_people, german_people
// ----
//

//
// [[data-aggregation-example]]
// === Using a pipeline to perform aggregations and return tabular data and graphs
//
// This example shows how to aggregate detailed sales data within a graph -- in effect, performing a 'roll-up' -- in order to obtain a high-level summarized view of the data, stored and returned in another graph, as well as returning an even higher-level view as an executive report.
// The summarized graph may be used to draw further high-level reports, but may also be used to undertake 'drill-down' actions by probing into the graph to extract more detailed information.
//
// Assume we have the graph *SalesDetail*, representing the sale of products in stores across various regions:
//
// image::opencypher-SalesDetail-graph.jpg[Graph,800,700]
//
// This models the following entities:
//
// * Regions may have many stores.
// * Stores:
// ** A store is identified by a unique `code`.
// ** A store is contained in exactly one region.
// ** A store may have multiple orders.
// * Products:
// ** A product is identified by a unique `code`.
// ** A product has a `RRP` property (Recommended Retail Price).
// ** A product may appear in one or more orders as a product _item_.
// * Sales orders:
// ** An order is identified by a unique order number, given by `num`.
// ** The `YYYYMM` property represents the year and month portion of the date of the order.
// ** An order is associated with exactly one store and contains one or more product items, representing the fact that the product item was sold in the store and is a part of the order.
// ** The relationship of between an order and a product contains the following properties:
// *** `soldPrice`: the price at which the product item was actually sold (usually lower than the product's RRP).
// *** `numItemsSold`: the number of the actual product items sold in the order.
//
// The following pipeline will create a summarized view of this data, and store it in a new summary graph called *SalesSummary*.
//
// We begin by referencing the *SalesDetail* graph, and matching on all products in all orders for all stores in all regions.
//
// [source, cypher]
// ----
// FROM GRAPH SalesDetail AT ‘graph://...’
// MATCH (p:Product)-[r:IN]->(o:Order)<-[HAS]-(s:Store)-[:IN]->(reg:Region)
// ----
//
// We aggregate the (tabular) data across all orders in order to obtain the total sales amount grouped by the product, store and region, and alias this value as `storeProductTotal`.
// As this tabular data is required to populate the summary graph later on, we pass it further down the pipeline:
//
// [source, cypher]
// ----
// WITH reg.name AS regionName,
//      s.code AS storeCode,
//      p.code AS productCode,
//      sum(r.soldPrice * r.numItemsSold) AS storeProductTotal
// ----
//
// The tabular data consists of the following:
//
// [source, cypher]
// ----
// +------------+-----------+-------------+-------------------+
// | regionName | storeCode | productCode | storeProductTotal |
// +------------+-----------+-------------+-------------------+
// | APAC       | AC-888    | PEN-1       | 20.00             |
// | APAC       | AC-888    | TOY-1       | 45.00             |
// | EMEA       | LK-709    | BOOK-2      | 10.00             |
// | EMEA       | LK-709    | TOY-1       | 40.00             |
// | EMEA       | LK-709    | BOOK-5      | 15.00             |
// | EMEA       | WW-531    | BOOK-5      | 18.00             |
// | EMEA       | WW-531    | BULB-2      | 190.00            |
// | EMEA       | WW-531    | PC-1        | 440.00            |
// +------------+-----------+-------------+-------------------+
// 8 rows
// ----
//
// Next, we read from the *SalesDetail* graph to get the store, product and region information:
//
// [source, cypher]
// ----
// MATCH (p:Product)-[:IN]->(o:Order)<-[:HAS]-(s:Store)-[:IN]->(r:Region)
// ----
//
// We now create a new graph, *SalesSummary*, containing the summarized view of the sales information across regions, products and stores:
//
// [source, cypher]
// ----
// INTO NEW GRAPH SalesSummary
// MERGE (s:Store {storeCode: s.code})
// MERGE (r:Region {name: r.name})
// MERGE (p:Product {productCode: p.code, RRP: p.RRP})
// MERGE (s)-[:IN]->(r)
// MERGE (p)-[:SOLD_IN]->(s)
//
// // Get the total amount sold for a store
// WITH storeCode, sum(storeProductTotal) AS totalSales
// // Get the total amount sold for a product
// WITH productCode, sum(storeProductTotal) AS soldTotal
//
// // Update all store nodes with the new totalSales property
// MATCH (s:Store)
// SET s.totalSales = totalSales
// WHERE s.code = storeCode
//
// // Update all product nodes with the new soldTotal property
// MATCH (p:Product)
// SET p.soldTotal = soldTotal
// WHERE p.code = productCode
//
// // Update all (:Product)-[SOLD_IN]->(:Store) relationships with the new sold property
// MATCH (p:Product)-[r:SOLD_IN]->(s:Store)
// SET r.sold = storeProductTotal
// WHERE p.code = productCode
// AND s.code = storeCode
// ----
//
// As a final step, the *SalesSummary* graph is returned, along with a high-level summarized tabular view of store sales data.
//
// [source, cypher]
// ----
// RETURN regionName,
//        storeCode,
//        sum(storeProductTotal) AS totalStoreSales
// GRAPH SalesSummary
// ----
//
// The *SalesSummary* graph is comprised of the following:
//
// image::opencypher-SalesSummary-graph.jpg[Graph,800,700]
//
// The high-level summarized tabular data consists of the following:
//
// [source, cypher]
// ----
// +------------+-----------+-----------------+
// | regionName | storeCode | totalStoreSales |
// +------------+-----------+-----------------+
// | APAC       | AC-888    | 65.00           |
// | EMEA       | LK-709    | 65.00           |
// | EMEA       | WW-531    | 648.00          |
// +------------+-----------+-----------------+
// 3 rows
// ----
//
// We note that the *SalesSummary* graph can be used to generate further high-level sales summaries, such as the total sales of a particular product (shown <<data-aggregation-external-example, here>>), as well as more detailed views.
//
// ._The full aggregation query pipeline is given by_:
// [source, cypher]
// ----
// FROM GRAPH SalesDetail AT ‘graph://...’
// MATCH (p:Product)-[r:IN]->(o:Order)<-[HAS]-(s:Store)-[:IN]->(reg:Region)
//
// WITH reg.name AS regionName,
//      s.code AS storeCode,
//      p.code AS productCode,
//      sum(r.soldPrice * r.numItemsSold) AS storeProductTotal
//
// MATCH (p:Product)-[:IN]->(o:Order)<-[:HAS]-(s:Store)-[:IN]->(r:Region)
//
// INTO NEW GRAPH SalesSummary
// MERGE (s:Store {code: s.code})
// MERGE (r:Region {name: r.name})
// MERGE (p:Product {code: p.code, RRP: p.RRP})
// MERGE (s)-[:IN]->(r)
// MERGE (p)-[:SOLD_IN]->(s)
//
// // Get the total amount sold for a store
// WITH storeCode, sum(storeProductTotal) AS totalSales
// //Get the total amount sold for a product
// WITH productCode, sum(storeProductTotal) AS soldTotal
//
// // Update all store nodes with the new totalSales property
// MATCH (s:Store)
// SET s.totalSales = totalSales
// WHERE s.code = storeCode
//
// // Update all product nodes with the new soldTotal property
// MATCH (p:Product)
// SET p.soldTotal = soldTotal
// WHERE p.code = productCode
//
// // Update all (:Product)-[SOLD_IN]->(:Store) relationships with the new sold property
// MATCH (p:Product)-[r:SOLD_IN]->(s:Store)
// SET r.sold = storeProductTotal
// WHERE p.code = productCode
// AND s.code = storeCode
//
// RETURN regionName,
//        storeCode,
//        sum(storeProductTotal) AS totalStoreSales
// GRAPH SalesSummary
// ----
//
// [[data-aggregation-external-example]]
// === Using a pipeline in an external execution context
//
// We show how a pipeline may be used in an external execution context; i.e. where processes external to the pipeline -- for example, an SQL query engine invoking a Cypher query as a graph function, or an automated business workflow system -- can be used to orchestrate externally query composition within the pipeline.
//
// Assume that the pipeline defined <<data-aggregation-example, above>> has executed and produced the *SalesSummary* graph, and that there is in scope a table, populated by some external process, containing the following list of codes (given by 'product_code') of the products of interest:
//
// [source, cypher]
// ----
// TOY -1
// BOOK-5
// BULB-2
// ----
//
// We obtain the graph and the table:
//
// [source, cypher]
// ----
// WITH product_code AS productCode GRAPH SalesSummary
// FROM GRAPH SalesSummary
// ----
//
// We then match the products in the *SalesSummary* graph with the ones from the input table, and produce a high-level report on the sales by product for only those products:
//
// [source, cypher]
// ----
// MATCH (p:Product)
// WHERE p.code = productCode
// RETURN p.code AS productCode, p.soldTotal AS totalProductSales
// ----
//
// The resulting 'sales by product' report contains:
//
// [source, cypher]
// ----
// +-------------+-------------------+
// | productCode | totalProductSales |
// +-------------+-------------------+
// | TOY-1       | 85.00             |
// | BOOK-5      | 33.00             |
// | BULB-2      | 190.00            |
// +-------------+-------------------+
// 3 rows
// ----
//



== Considerations


=== Interaction with existing features

This proposal is far reaching as it changes both the property graph model and the execution model of the language.

However, the change has been carefully designed to not change the semantics of existing queries.


=== Alternatives

Instead of considering entities to only belong to a single graph, we could explore a model where an entity can be part of multiple graphs.
This has the drawback of not being able to easily address an entity in a single graph and as a consequence it becomes impossible to distinguish entities according to the graph from which they have been matched.
Committing to a model of sharing of identical, self-same entities only limits the flexibility in terms of future extensions to provenance tracking such as clone variations (clones with different properties).
Furthermore, establishing a 1:1 relationship between entities and graphs grants great implementation freedom, especially in terms of id space management.

Instead of only returning either a table or a single graph, an earlier edition of this proposal explored to return table-graphs, i.e. both a single driving table and an associated set of multiple, named graphs.
This felt overly complicated and made it difficult to distinguish between graphs in scope and variables in scope, created the need to occasionally create dummy values (like an empty graph or driving table), and led to a more complex execution result (with potentially difficult repercussions for the network protocol).

Instead of only establishing a single working graph, an earlier edition of this proposal explored the idea of distinguishing between a graph for reading and a graph for writing.
This led to a more complex execution result, made it necessary to manage those two graphs and complicated the users mental model, and was ultimately discarded based on a use-case analysis that indicated that in practice queries would typically first select graphs for reading and then switch to writing.

Instead of introducing graphs as separate catalog objects, an earlier edition of this proposal considered graphs as values (called graphlets).
While providing great flexibility, this approach becomes very difficult to plan and statically analyze.
It also leads to intractable operations like joins between graphs.
However it may still be worthwhile to explore this idea in the future for "tiny subgraphs".


=== What others do

SPARQL only provides basic facilities for returning graphs using `CONSTRUCT`.
SPARQL avoid the need for `CLONE` by using global entity identities at the peril of having to use graph relationships to associate various attributes to them.

SQL constructs derived tables using projection, aggregation, and filtering.

Neither Gremlin nor PGQL have developed facilities for the direct construction and manipulation of graphs.


=== Benefits to this proposal

Cypher is evolved to become a query language that is properly closed under graphs and tables.


=== Caveats to this proposal

This is a fundamental and large change to the language whose long-term consequences are difficult to assess.
