= CIP2017-06-18 Multiple Graphs
:numbered:
:toc:
:toc-placement: macro
:source-highlighter: codemirror

*Author:* Stefan Plantikow <stefan.plantikow@neo4j.com>, Andres Taylor <andres.taylor@neo4j.com>, Petra Selmer <petra.selmer@neo4j.com>

This material is based on internal contributions of Alastair Green <alastair.green@neotechnology.com>, Mats Rydberg <mats.rydberg@neotechnology.com>, Martin Junghanns <martin.junghanns@neotechnology.com>, Tobias Lindaaker <tobias.lindaaker@neotechnology.com>

[abstract]
.Abstract
--
This CIP extends Cypher with support for working with multiple graphs.
Different graphs may be queried in a single statement by selecting them by name from a global catalog.
New graphs may be created in the catalog or constructed temporarily during the course of a query.
Support for multiple graphs rests on a newly introduced multiple property graph model and a formalization of Cypher's clause structure and query execution model.

Working with multiple graphs requires relating entities from otherwise disconnected datasets.
This is supported by the accompanying CIP2018-04-24 for content based comparison.
--

toc::[]

// TODO: Better explain cloning and equality relationship
// TODO: Emulate construct on via union
// TODO: CONSTRUCT ON business
// TODO: CONSTRUCT ON graph vs CONSTUCT NEW
// TODO: TRANSFORM
// TODO: CREATE VIEW

== Introduction

Cypher today is a query language for property graphs that provides access to a single, global, implicit graph in order to extract, transform, and return tabular data that is derived from it.
While such returned tabular data may include graph entities (such as nodes and relationships), in essence Cypher as a language is not closed under graphs and as a consequence, Cypher queries are not yet (graph) compositional.

However it seems desirable that a language for property graphs should not only enable querying and updating a selected graph but should also support the construction and transformation of multiple graphs, ideally by utilizing a mechanism for incremental query composition.

Furthermore, adding support for working with multiple graphs has recently been identified as a frequently requested feature:

* It enables the dynamic construction of graph views (e.g. for access control)
* It allows reasoning over multiple versions of the same graph (e.g. comparing daily snapshots)
* It provides an effective grouping mechanism for naturally-partitioned data (e.g. per-continent graph)
* It is useful for combining data from disparate data sources in one system (e.g. in federation and data integration scenarios)
* It fits the paradigm of prominent analytical big-data processing systems (e.g. Apache Spark)
* It mirrors mathematical graph theory where working with multiple graphs is common

// === Overview
=== Related work

This CIP has been developed in tandem with

 * `CIP2018-05-03`: Nested subqueries
 * `CIP2018-05-04`: Equivalence operators



== The data model

The data model underpinning Cypher today is the _property graph model_.
We give a brief overview of the current property graph model in XXLINK, in effect, the _single property graph data model_, and then describe extensions to the model that will allow for the support of multiple graphs in XXLINK.


=== The single property graph data model (current)

The property graph model today is predicated upon the notion of a single, implicit property graph (hereafter termed as 'graph')[https://arxiv.org/pdf/1802.09984.pdf, adoc], which we show in IMAGE_FROM_SLIDES-SINGLE-PGMxxx.

The concept of implicitness implies that:

 * the graph is an unnamed or anonymous entity,
 * the data model contains nothing apart from this single graph, and
 * the graph is not able to be referred to by virtue of a name or identity or address within any context.

IMAGE_FROM_SLIDES-SINGLE-PGMXXX

We define below terms which underpin the property graph data model:

A _**property graph**_ consists of a set of nodes and a set of relationships that connect the nodes of the property graph.

A _**property graph model instance**_ contains a single property graph.
A property graph is contained in exactly one property graph model instance.

A _**model element**_ is a constituent of a property graph model instance.
These comprise nodes and relationships.

A _**label**_ is a name used to classify a node.

A _**relationship type**_ is a name used to classify a relationship.

A _**value**_ is any value that is supported by the Cypher type system.

A _**property**_ is a tuple consisting of a name (called the _**property key**_) and a value (called a _**property value**_).

An _**identity**_ is a value that is used to identify individual model elements and to distinguish between multiple model elements from a set of model elements in a given scope.

A _**node**_ has a _**node identity**_ which is an identity that uniquely identifies the node within a property graph.
A node contains a set of zero or more labels and zero or more properties with mutually different property keys.

A _**relationship**_ has a _**relationship identity**_ which is an identity that uniquely identifies the relationship within a property graph.
A relationship contains a start node and an end node (both drawn from the same graph as the relationship), a single relationship type, and zero or more properties with mutually different property keys.
We note that the start and end nodes may be the same node, hence denoting a ‘self-loop’ relationship

XXTODO
// Content = Everything but the identity
// ???     = Content + Id
// FOO ( ID, BAR ( ID + STUFF ), MAZ ( ID + THINGS ) )
// content( FOO ) = BAR ( ID + STUFF ), MAZ ( ID + THINGS ) )

// content( FOO ) = all ids gone
//
The constituents of a model element are called its _**content**_.
For a node (respectively relationship) this comprises its labels, identity and properties (respectively, its relationship type, identity and properties).

Nodes and relationships are called _**entities**_.

Node and relationship identities are called _**entity identities**_.

A _**reference**_ is a handle (i.e. an otherwise opaque value) that is used to address model elements of a property graph model instance (i.e. a node or a relationship).


=== The multiple property graph data model (proposed)

We now describe the extensions required to the property graph data model to enable multiple graph support.
Unless otherwise specified, all previous attributes for the extended terms hold.

IMAGE_FROM_SLIDES-SINGLE-MPGM

A _**multiple property graph model instance**_ (extending the notion of a property graph model instance) is a set of zero or more property graphs.

A _**property graph**_ has a _**graph identity**_ which is an identity that uniquely identifies the graph such that it is able to be distinguished from other graphs in the same multiple property graph model instance.
A property graph is contained in exactly one multiple property graph model instance.

A _**model element**_ is a constituent of a multiple property graph model instance.
These additionally comprise property graphs.

The _**content**_ of a property graph comprises its graph identity.
XXCHECK

A _**node**_ is contained in exactly one property graph.

A _**relationship**_ is contained in exactly one property graph and its start node and end node are both contained in the same property graph as the relationship.


==== Valid model instance

The set of *atoms* of an arbitrary value `v` (named `atoms(v)`) is defined as follows:

 * If `v` is a scalar value, `atoms(v) = {v}`
 * If `v` is a list value `[e~1~, e~2~, ..., e~n~]`, `atoms(v) = {v} UNION atoms(e~1~) UNION atoms(e~2~) UNION ... UNION atoms(e~n~)`
 * If `v` is a map or a node or a relationship with `values(v)`, `atoms(v) = {v} UNION atoms(values(v))`
 * Nothing else

A *valid* multiple property graph model instance adheres to the following restrictions:

 * The set of atoms of an identity of any model element must not contain `NULL`.
 * The set of atoms of an identity of any model element must not contain a reference to a model element.
 * Property values must not be `NULL`.
   (Note that this differs from an entity not having a property key)
 * The set of atoms of any property value of any entity must not contain a reference to a model element.



== Query structure

Cypher syntax describes a structure that is a tree of clauses.


=== Statements and clauses

_Definition_: A *valid statement* is a statement that is valid according to the semantic rules of the Cypher property graph query language.

_Definition_: A *statement* is a source program that is a syntactically valid term according to the root production rule of the grammar of the Cypher property graph query language.
A statement may either be a statement chain or a single statement.

_Definition_: A *statement chain* is a single statement followed by a semicolon followed by another statement.

_Definition_: A *single statement* is either an *operator clause chain* or a *simple clause chain*.

_Definition_: An *operator clause chain* are two or more simple clause chains that are separated by the exact same operator clause.

_Definition_: An *operator clause* is a clause that is used to connect multiple simple clause chains in an operator clause chain.

Note:: As per this and all accompanying proposals, the list of current and proposed operator clauses is `UNION`, `UNION ALL`, `INTERSECT`, `EXCEPT`.

_Definition_: A *simple clause chain* is a sequence of one or more non-operator clauses which each may be further qualified by clause arguments, sub-clauses and sub-clause arguments.


=== Clause classification

_Definition_: Clauses may be classified according to their side-effects as either

 * *reading clauses* that read data
 * *updating clauses* that read and update data
 * *schema clauses* that only read from and update the schema

_Definition_: Clauses that are used for graph construction are called *constructing clauses*.
Constructing clauses are considered to be a form of reading clauses.


=== Statement classification

_Definition_: A (single) statement may be categorized as:

 * A *reading query* is a statement consisting of reading clauses that reads and returns data
 * An *updating query* is a statement consisting of reading and updating clauses that reads, updates and returns data
 * An *updating command* is a statement consisting of reading and updating clauses that reads and updates data but returns no data
 * A *schema command* is a statement consisting of schema clauses that only updates the schema

 Note:: An implementation may choose to limit the kinds of statements that can be combined in a statement chain (e.g. not allow to combine updating and schema commands in one chain).


=== Structural principles

The high-level syntactic structure of Cypher adheres to the following principles:

1. The majority of clauses is given in sequential order that is to be interpreted from top to bottom in order to construct a left leaning clause tree.

2. The end of a syntactic unit or a subquery that returns data is always marked explicitly using `RETURN` or `RETURN GRAPH`.

3. The end of a syntactic unit or a subquery that returns no data is marked explicitly by choosing an updating clause as the final clause and the absence of `RETURN` or `RETURN GRAPH` as a final clause

4. Non-sequential operator clauses (like `UNION`) are only allowed at the top-level and may not be combined with other operator clauses (This can be achieved though via nested subqueries, cf. accompanying `CIP2018-05-03`).

5. Updating clauses and following reading clauses must be separated by `WITH`.

6. Not all clauses are allowed in all contexts.



== Execution model

_Definition_: A *query processor* is a query processing service that executes a source program on behalf of a *client* and provides the client with the *execution result* that describes the outcome of executing the source program.
A query processor maintains exactly one _multiple property graph model instance_.
A query processor maintains exactly one _catalog_.


=== Execution of client requests


==== Query inputs and outputs

_Definition_: A source program together with statement parameters is called a *client request*.

_Definition_: A set of parameters with pairwise different names is called *statement parameters*.

_Definition_: A *parameter* is tuple of name and a value.

_Definition_: The result of executing a client request is called an *execution result*.
An execution result is one of

* a *tabular result*; i.e. a collection of records where each record has the exact same set of named fields.
Tabular results may contain duplicate results and may optionally be ordered
* a *graph result*; i.e. the contents of a graph as described by its set of nodes and relationships
* an *execution error*; i.e. a message describing the reason that prevented the query processor from executing the client request correctly

_Definition_: An *empty result* is a specially marked tabular result that consists of one and only one record with zero fields.

_Definition_: Any tabular result that is provided as the single input to a clause is called the *driving table* of that clause.


==== Request execution

Clients interact with the query processor by submitting a client request.
The source program is then executed by the query processor and an execution result is returned to the client for consumption.

_Definition_: *Raising an error* refers to aborting the execution of a currently-executing client request and returning the error as the final execution result of the client request back to the client.

An execution error is raised if the client request does not contain a semantically valid statement.


==== Execution of statement chains

Statement chains are executed by executing all contained single statements in the order given.
If execution of any contained single statement fails with an error, the execution of the whole statement fails with the same error.
Otherwise, the query processor discards all intermediary results produced by a statement chain and only returns the execution result for the last single statement.


==== Identity validity during execution

Identities are only guaranteed to be valid for the duration of executing a statement and consuming its result.

Implementations may choose to guarantee the validity of identities across multiple client requests.

Note:: As a consequence, the same identity value may refer to different model elements in results returned by different client requests.


==== Returning graph model elements

If an execution result that is returned _to the client_ contains a model element, this model element is returned together with its content at the time of terminating the query (i.e. the client always receives the current content of all model elements).

Note:: Additionally, a result may contain implementation specific metadata such as a summary of performed update activity (e.g. the number of nodes created) or a detailed query plan.


=== Catalog

_Definition_: A _catalog_ is a mapping from *fully qualified graph names* to graph references.
Multiple entries in the catalog may refer to the same graph.

A fully qualified graph name should use the syntax for dotted variable identifiers and consists of an optional *graph namespace*, and a mandatory *graph name*.

Note:: In practice, a query processor might have a catalog shared by all users, or provide a different catalog for each user.
This is not considered here based on the simplifying assumption that all client requests are made by the same user.


=== Working graph

Most Cypher clauses operate within the context of a *working graph*, by reading or updating it.

_Definition_: The _working graph stack_ is a stack of graph references that is maintained during statement execution.

_Definition_: The _working graph_ is the top most element of the current working graph stack.

Note:: The working graph stack may be empty at the start of executing a statement.
In this case, the working graph is considered to be unset.

A query processor may choose to establish an *initial working graph* for each executed statement.
The details of this are left to implementations.

If a query processor has not established an initial working graph (i.e. the working graph is unset) and the statement fails to set a working graph explicitly before attempting to operate on the working graph, an error is raised.



== Basic graph operations

The working graph may be operated on in the following ways:

* The working graph can be changed by selecting a graph that is known by the catalog.
* The working graph is implicitly used during pattern matching and creational activity.
* The working graph may be returned as a query result.
* The working graph can be kept while the binding table is discarded.
* The identity of model elements in the context of the working graph may be obtained using various reflective functions.


=== Selecting the working graph from the catalog for querying

// TODO: Asciidoc circle references
// TODO: Asciidoc line numbers
The working graph may be changed for all subsequent querying clauses using two forms:

[source, cypher]
----
[1] FROM < graph-name >
[2] FROM GRAPH
----

`<graph-name>` is expected to be the name of a graph in the catalog.
If `<graph-name>` is not the name of a graph in the catalog, an error is raised.
It is an error to perform an updating operation on a working graph that was introduced using `FROM [GRAPH]`.

Additionally, `FROM GRAPH` may be used to select the working graph for further read-only operations.

Note:: A subquery form of `FROM` is proposed in the accompanying `CIP2018-05-03`.


=== Selecting the working graph from the catalog for updating

The working graph may be changed for all subsequent querying and updating clauses using two forms:

[source, cypher]
----
[1] UPDATE < graph-name >
[2] UPDATE GRAPH
----

`<graph-name>` is expected to be the name of a graph in the catalog.
If `<graph-name>` is not the name of a graph in the catalog, an error is raised.
It is an error to not perform at least a single updating operation on a working graph that was introduced using `UPDATE [GRAPH]`.

Additionally, `UPDATE GRAPH` may be used to select the working graph for further updating operations.

Note:: A subquery form of `UPDATE` is proposed in the accompanying `CIP2018-05-03`.


=== Using the working graph when interpreting a pattern

All bound entities are matched against the working graph in both pattern matching and updating commands.

If one of the bound variables in a pattern is an entity that is not contained in the working graph, the whole pattern does not match.

An error is raised, if a statement attempts to update an entity that is not contained in the working graph.

=== Copy patterns

A new type of pattern that is called a *copy pattern* may be used to copy all labels and properties of a node or the relationship type and all properties of a relationship.
The syntax of copy patterns is:

[source, cypher]
----
MATCH (a)-[r]->(b)
FROM another_graph
MATCH (x COPY OF b)-[COPY OF r]->()
...
----

Copying relationships ignores the start and the end node of the relationship.

Copy patterns may be used in updating statements.


=== Discarding the binding table

The current binding table may be discarded while retaining the working graph using the following syntax:

[source, cypher]
----
WITH GRAPH
...
----

The remainder of the query after `WITH GRAPH` continues to operate on the same working graph but using an empty binding table (no fields, single record).


=== Returning a graph result

The working graph may be returned as an execution result using:

[source, cypher]
----
RETURN GRAPH
----

Additionally, the following syntactic form is supported for selecting the working graph from the catalog and returning it at the same time:

[source, cypher]
----
RETURN GRAPH < graph-name >
----

Graphs are always returned by reference during execution inside the query processor.
This does not affect the rules on returning model elements together with their content to the client which ensure that a graph result will be returned by value to the client.


=== Functions for data model introspection

The data model may be introspected using the following functions:

The `graph()` function returns the *graph identity* of the working graph.

The `graph(e)` function returns the *graph identity* of the base graph in which the root original of `e` was created.

The `exists(e)` function is overloaded for entities `e` such that it returns `true` if `e` has not been deleted in `graph(e)` and is also overloaded such that it returns `false` otherwise.

The `contains(e)` function is defined for entities `e` such that it returns `true` if either a clone of the given entity `e` or `e` itself is contained in the working graph and is also defined such that it returns `false` otherwise.

The `id(n)` function returns the *node identity* of the representing clone in `graph(n)`

The `id(r)` function returns the *relationship identity* of the representing clone in `graph(r)`



== Graph construction

*Graph construction* dynamically constructs a new graph in order to query it, update it, store it in the catalog, or return it to the client.

The following forms of graph construction are proposed in this section:

* The working graph can be changed by constructing a new graph.
* The working graph can be changed by constructing a disjoint graph union.
* The working graph can be changed by constructing a common graph union.
* The working graph can be changed by constructing a graph intersection.
* The working graph can be changed by constructing a graph difference.


=== Graph projection

Graph projection is the dual operation to graph matching: While graph matching extracts pattern instances into variable bindings from the working graph, graph projection builds a new working graph from variable bindings.

All newly created nodes and relationships in the projected graph have new entity identities and are different from any previously matched entities.

The basic form of graph construction is:

[source, ebnf]
----
< graph-construction > :=
  < construct-clause >
  < update-command | clone-clause >*
  [WITH ... | WITH GRAPH | RETURN ... | RETURN GRAPH ]
  ;

< construct-clause > :=
  CONSTRUCT
    [ON GRAPH]
    [ON < graph-name-list > ]
  ;

< graph-name-list > := < graph-name > [ ',' < graph-name > ]* ;

< clone-clause > :=
  CLONE < clone-item-list > | '*' ;

< clone-item-list := < clone-item > [ ',' < clone-item > ]*
< clone-item > :=
  ( < expr > [AS < alias >] | < variable > ) ;
----

Graph construction supports a sub-clause for the *cloning of existing graphs* and a clause for the *cloning of existing entities*.

A single statement may end in a `<graph-construction>`.


==== Cloning

In order to reconstruct subgraph structures from other graphs in the new graph, `CONSTRUCT` supports the creation of *cloned entities* in the new graph.

_Definition_: *Cloning* ensures that exactly one new entity (called a *clone*) is created in the new graph for a given cloned entity (called its *source*) from a source graph.
If the same source is cloned multiple times this will still only create one clone in the new graph.
Every clone has exactly the same labels or relationship type as well as the same properties as the source (i.e. a clone can be seen as a "representative" of the source in the new graph).
Cloning a relationship implicitly clones its start node and its end node and uses these clones as the start node and the end node of the relationship clone.

_Definition_: It is possible to clone an entity over multiple steps of graph construction.
In that case, if multiple entities are cloned into the same graph that in turn are both clones of a shared source, only one entity is created for these entities.
This is called *provenance tracking*.

The `ON GRAPH` sub-clause may be used to clone all nodes and relationships from the working graph into the new graph.

The `ON < graph-name-list >` sub-clause may be used to clone all nodes and relationships from the given graphs in the catalog into the new graph.

The `CLONE < clone-item-list >` clause may be used to clone entities that are contained in the atoms of a given value and optionally bind that value to new variable.
Additionally, the `CLONE *` sub-clause may be used to clone all variables that are visible in the current scope.

Note:: Cloning a nested value (like a path) implicitly clones all contained nodes and relationships.


==== Building constructed graphs

Constructed graphs are built by explicitly populating them with entities using the following clauses:

 * `CREATE`
 * `MERGE`
 * `SET`
 * `REMOVE`
 * `[DETACH] DELETE`

If an entity from another graph is referenced by a pattern in `CREATE`, it is cloned.

If an entity from another graph is referenced by a pattern in `MERGE`, it is cloned.

If an entity from another graph is passed as argument to `DELETE` or `DETACH DELETE`, any corresponding clones are removed from the constructed graph.

An error is raised for any attempt to `SET` or `REMOVE` labels or properties of cloned entities during graph construction.


==== Updating constructed graphs

Constructed graphs may be updated as well using `UPDATE GRAPH`.

Updating relies on information from provenance tracking of cloned nodes in order to propagate updates to base data.

Constructed graphs may only be updated by

 * setting and removing properties
 * setting and removing labels
 * deleting nodes and relationships

An error is raised if an update to a constructed graph leads to a constraint violation in a source graph.


=== Disjoint graph union

The *disjoint graph union* of two graphs may be computed using the following syntax:

[source, cypher]
----
< query-1 >
RETURN GRAPH
UNION ALL
< query-2 >
RETURN GRAPH
----

The resulting union graph consists of copies of all entities from the two input graphs.

Note:: If a clone of the same source node is contained in both graphs, still two copies of that node are added to the result graph.


=== Graph union

The *common graph union* of two graphs may be computed using the following syntax:

[source, cypher]
----
< query-1 >
RETURN GRAPH
UNION
< query-2 >
RETURN GRAPH
----

The resulting union graph consists of clones of all entities from the two input graphs.

Note:: If a clone of the same source node is contained in both graphs, only one clone for that node is added to the result graph.


=== Graph intersection

The *common graph intersection* of two graphs may be computed using the following syntax:

[source, cypher]
----
< query-1 >
RETURN GRAPH
INTERSECT
< query-2 >
RETURN GRAPH
----

The resulting intersection graph consists of clones of all entities that are contained in both input graphs.


=== Graph difference

The *common graph difference* of two graphs may be computed using the following syntax:

[source, cypher]
----
< query-1 >
RETURN GRAPH
EXCEPT
< query-2 >
RETURN GRAPH
----

The resulting difference graph consists of clones for all entities from the left (first) graph that are not contained in the second (last) graph.



== Creating and administrating graphs in the catalog


=== Creating empty graphs

Creating a new, empty graph in the catalog is done using the new catalog command `CREATE GRAPH <graph-name>`.
If `<graph-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Creating new graphs and populating them from a query

`CREATE GRAPH <graph-name>` may be optionally followed by a subquery that returns a graph.
In that case, a new graph `<graph-name>` is created in the catalog for the graph returned by the subquery.
All entities in the new graph are considered to be copies of the entities in the returned graph (i.e. they are unrelated from the entities in the graph returned by the subquery in terms of provenance).
If `<graph-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Delete graph

The catalog command `DELETE GRAPH <graph-name>` deletes the graph with the name `<graph-name>` from the catalog.
If `<graph-name>` is not the name of a graph that already exists in the catalog, an error is raised.


=== Copy graph

The catalog command `COPY <old-name> TO <new-name>` copies the content and the schema of the graph with the name `<old-name>` in the catalog to a new graph with the name `<new-name>` in the catalog.
If `<old-name>` is not the name of a graph that already exists in the catalog, an error is raised.
If `<new-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Rename graph

The catalog command  `RENAME <old-name> TO <new-name>` removes the graph with the name `<old-name>` from the catalog and adds it as a new graph with the name `<new-name>` in the catalog.
If `<old-name>` is not the name of a graph that already exists in the catalog, an error is raised.
If `<new-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Truncating graphs

The catalog command `TRUNCATE <graph-name>` truncates the graph with the name `<graph-name>` in the catalog.

Truncating a graph deletes all its nodes and relationships but retains any additional schema information like constraints.


=== Determining the name of a graph

The `catalog()` function returns the catalog name for the working graph or `NULL` if the working graph is a dynamically constructed graph.

 The `catalog(g)` function returns the catalog name for the graph identity `g` or `NULL` if `g` is a dynamically constructed graph.

The `failIfNull(value, message)` function returns `value` if `value` is not `NULL` and raises an error with the given message `message` otherwise.

Note:: `toString(graph())` may be used to just generate a human readable name for the working graph.


== Examples

The following examples are intended to show how multiple graphs may be used, and focus on syntax.
We show two fully worked-through examples <<data-integration-example, here>> and <<data-aggregation-example, here>>, describing and illustrating every step of the pipeline in detail.

=== Creating and returning a new graph: a simple example

This query returns a graph containing all the people living in Berlin in the `persons` graph and their `KNOWS` relationships.

[source, cypher]
----
FROM persons
MATCH (a:Person {city: "Berlin"})-[r:KNOWS]->(b:Person {city: "Berlin"})
CONSTRUCT
CLONE a, b, r
RETURN GRAPH
----

By specifying the same predicate "{city: "Berlin"}" on both nodes, we are saying we are only interested in the graph of people in Berlin.

Another query we might want to do is to see all the people that live in Berlin, and also include all their known nodes, no matter where they live.

[source, cypher]
----
FROM persons
MATCH (a:Person {city: "Berlin"})-[r:KNOWS]-(b:Person)
CONSTRUCT
CLONE a, b, r
RETURN GRAPH
----

=== Creating a new graph, switching contexts and returning a graph

[source, cypher]
----
FROM social-network
// .. and match some data
MATCH (a:Person)-[:KNOWS]->(b:Person)-[:KNOWS]->(c:Person) WHERE NOT (a)--(c)
CONSTRUCT
CREATE (a)-[:POSSIBLE_FRIEND]->(c)
// All cardinality and bindings are removed here
MATCH (a:Person)-[e:POSSIBLE_FRIEND]->(b:Person)
// Return tabular and graph output
RETURN a.name, b.name, count(e) AS cnt ORDER BY cnt DESC
----


[[data-integration-example]]
=== A complete example illustrating a data integration scenario

Assume we have two graphs, *ActorsFilmsCities* and *Events*.
This example will show how these two graphs can be integrated into a single graph.

The *ActorsFilmsCities* graph models the following entities:

* Actors and people fulfilling other roles in the film-industry.
* Films in which they acted, or directed, or for which they wrote the soundtrack.
* Cities in which they were born.
* The relationships between family members and colleagues.

Each node is labelled and contains one or two properties (where `YOB` stands for 'year of birth'), and each relationship of type `ACTED_IN` has a `characterName` property indicating the name of the character the relevant `Actor` played in the `Film`.

image::opencypher-PersonActorCityFilm-graph.jpg[Graph,800,650]

The other graph, *Events*, models information on events.
Each event is linked to an event type by an `IS_A` relationship, to a year by an `IN_YEAR` relationship, and to a city by an `IN_CITY` relationship.
For example, the _Battle of Britain_ event is classified as a _War Event_, occurred in the year _1940_, and took place in _London_.

In contrast to the *ActorsFilmsCities* graph, *Events* contains no labels on any node, no properties on any relationship, and only a single `value` property on each node.
*Events* can be considered to be a snapshot of data from an RDF graph, in the sense that every node has one and only one value; i.e. in contrast to a property graph, an RDF graph has properties on neither nodes nor relationships.
(For easier visibility, we have coloured accordingly the cities and city-related relationships, event types and event-type relationships, and year and year-related relationships.)

image::opencypher-Events-graph.jpg[Graph,800,600]

The aims of the data integration exercise are twofold:

* Create and persist to disk (for future use) a new graph, *PersonCityEvents*, containing an amalgamation of data from *ActorsFilmsCities* and *Events*.
*PersonCityEvents* must contain all the event information from *Events*, and only `Person` nodes connected to `City` nodes from *ActorsFilmsCities*.

* Return a graph containing a subset of the data from *PersonCityEvents*, consisting only of the criminal events, their associated `City` nodes, and `Person` nodes associated with the `City` nodes.

==== Step 1

The very first step is to create the graph in the catalog:

[source, cypher]
----
CREATE GRAPH PersonCityEvents
----

This creates an empty graph in the catalog named `PersonCityEvents`.


===== Step 2

The next step is to copy over persons and cities from `ActorsFilmsCities`.

[source, cypher]
----
[0] FROM ActorsFilmsCities
[1] MATCH (p1:Person)-[:BORN_IN]->(c1:City)
[2] UPDATE PersonCityEvents
[3] MERGE (p2:Person {name: p1.name, YOB: p1.YOB})
[4] MERGE (c2:City {name: c1.name})
[5] MERGE (p2)-[:BORN_IN]->(c2)
----

Here, we are first setting the working graph to the ActorsFilmsCities [0], and then we are matching on this graph [1].
That is all the input data we need, so we can now switch over to the output graph [2] and create nodes and relationships in it [3-5].
// TODO Maybe talk about that we could have used CONSTRUCT instead.

At this stage, *PersonCityEvents* is given by:

image::opencypher-PersonCity-graph.jpg[Graph,600,400]

==== Step 3

The next stage in the pipeline is to add the events information from *Events* to *PersonCityEvents*.

[source, cypher]
----
[ 0] FROM Events
[ 1] MATCH (c)<-[:IN_CITY]-(e)-[:IN_YEAR]->(y),
[ 2]       (e)-[:IS_A]->(et)
[ 3] WITH *, CASE et.value
[ 4]     WHEN 'Criminal Event' THEN 'criminal'
[ 5]     WHEN 'Public Event' THEN 'public'
[ 6]     WHEN 'War Event' THEN 'war'
[ 7]     WHEN 'Royal Event' THEN 'royal'
[ 8]   END as eventType
[ 9] UPDATE PersonCityEvents
[10] MERGE (c:City {name: c.value})
[11] MERGE (e:Event {title: e.value, year: y.value, type: eventType})
----

First, we specify that we start reading from the Events graph [0].
All the events information -- the event itself, its type, the year in which it occurred, and the city in which it took place -- is matched [1-2].

Next, we create a string value for the type of event, and store it in the variable `eventType`[3-8]

The target graph is set to the *PersonCityEvents* graph [9].

Using the results from the `MATCH` clause, we create a subgraph with more intelligible semantics through the transformation of the events information into a less verbose form through greater use of node-level properties.


*PersonCityEvents* now contains the following data:

image::opencypher-PersonCityEvents-graph.jpg[Graph,800,700]

==== Step 4

The last step in the data integration pipeline is to return part of the newly created graph - only the criminal events and related information is returned from *PersonCityEvents*.

[source, cypher]
----
[0] FROM PersonCityEvents
[1] MATCH
[2]  (ce:Event {type:'criminal'}),
[3]  (ce)-[h:HAPPENED_IN]->(c:City)<-[b:BORN_IN]-(p:Person)
[4] CONSTRUCT
[5] CLONE p, c, ce, h, b
[6] RETURN GRAPH
----

Again, we start from `PersonCityEvents` [0].

Next, obtain the subgraph of all criminal events -- i.e. nodes labelled with `Event` of type "criminal" [2] -- and their associated `City` nodes, and `Person` nodes associated with the `City` nodes [3].

And, as the final step of the entire data integration pipeline, return *Temp-PersonCityCrimes*, which is comprised of the following data:

This is the final step of the entire data integration pipeline, we return this graph [6].

image::opencypher-PersonCityCriminalEvents-graph.jpg[Graph,700,550]

// ._The full data integration query pipeline is given by_:


//
// === Using a pipeline of temporary graphs to process and return a subgraph
//
// [source, cypher]
// ----
// // Set scope to the whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data.
// MATCH (a:Person)-[:IS_LOCATED_IN]->(c:City),
//       (c)->[:IS_LOCATED_IN]->(co:Country),
//       (a)-[e:KNOWS]-(b)
//
// // Create a new temporary named graph,
// INTO NEW GRAPH sn_updated
// // add previous matches to new graph,
// CREATE (a)-[e]-(b)
// // update existing nodes.
// SET a.country = cn.name
// // ... and finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// FROM GRAPH sn_updated
// MATCH (a:Person)-[e:KNOWS]->(b:Person)
// WITH a.country AS a_country, b.country AS b_country, count(a) AS a_cnt, count(b) AS b_cnt, count(e) AS e_cnt
// INTO NEW GRAPH rollup
// MERGE (:Persons {country: a_country, cnt: a_cnt})-[:KNOW {cnt: e_cnt}]->(:Persons {country: b_country, cnt: b_cnt})
//
// // Return final graph output
// RETURN GRAPH rollup
// ----
//
// === A more complex pipeline: using and persisting multiple graphs
//
// [source, cypher]
// ----
// // Set scope to the whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data.
// MATCH (a:Person)-[e]->(b:Person),
//       (a)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c:Country {name: ‘Sweden’}),
//       (b)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c)
// // Create a persistent graph at 'graph://social-network/swe'
// INTO NEW GRAPH sweden_people AT './swe'
// // connecting persons that live in the same city in Sweden.
// CREATE (a)-[e]->(b)
//
// // Finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// MATCH (a:Person)-[e]->(b:Person),
//       (a)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c:Country {name: ‘Germany’}),
//       (b)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c)
// // Create a persistent graph at 'graph://social-network/ger'
// INTO NEW GRAPH german_people AT './ger'
// // connecting persons that live in the same city in Germany.
// CREATE (a)-[e]->(b)
//
// // Finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// // Start query on the 'sweden_people' graph
// FROM GRAPH sweden_people
// MATCH p=(a)--(b)--(c)--(a) WHERE NOT (a)--(c)
// // Create a temporary graph 'swedish_triangles'
// INTO NEW GRAPH swedish_triangles
// MERGE p
//
// // and return it together with a count of its content
// RETURN count(p) AS num_triangles GRAPHS swedish_triangles, sweden_people, german_people
// ----
//

//
// [[data-aggregation-example]]
// === Using a pipeline to perform aggregations and return tabular data and graphs
//
// This example shows how to aggregate detailed sales data within a graph -- in effect, performing a 'roll-up' -- in order to obtain a high-level summarized view of the data, stored and returned in another graph, as well as returning an even higher-level view as an executive report.
// The summarized graph may be used to draw further high-level reports, but may also be used to undertake 'drill-down' actions by probing into the graph to extract more detailed information.
//
// Assume we have the graph *SalesDetail*, representing the sale of products in stores across various regions:
//
// image::opencypher-SalesDetail-graph.jpg[Graph,800,700]
//
// This models the following entities:
//
// * Regions may have many stores.
// * Stores:
// ** A store is identified by a unique `code`.
// ** A store is contained in exactly one region.
// ** A store may have multiple orders.
// * Products:
// ** A product is identified by a unique `code`.
// ** A product has a `RRP` property (Recommended Retail Price).
// ** A product may appear in one or more orders as a product _item_.
// * Sales orders:
// ** An order is identified by a unique order number, given by `num`.
// ** The `YYYYMM` property represents the year and month portion of the date of the order.
// ** An order is associated with exactly one store and contains one or more product items, representing the fact that the product item was sold in the store and is a part of the order.
// ** The relationship of between an order and a product contains the following properties:
// *** `soldPrice`: the price at which the product item was actually sold (usually lower than the product's RRP).
// *** `numItemsSold`: the number of the actual product items sold in the order.
//
// The following pipeline will create a summarized view of this data, and store it in a new summary graph called *SalesSummary*.
//
// We begin by referencing the *SalesDetail* graph, and matching on all products in all orders for all stores in all regions.
//
// [source, cypher]
// ----
// FROM GRAPH SalesDetail AT ‘graph://...’
// MATCH (p:Product)-[r:IN]->(o:Order)<-[HAS]-(s:Store)-[:IN]->(reg:Region)
// ----
//
// We aggregate the (tabular) data across all orders in order to obtain the total sales amount grouped by the product, store and region, and alias this value as `storeProductTotal`.
// As this tabular data is required to populate the summary graph later on, we pass it further down the pipeline:
//
// [source, cypher]
// ----
// WITH reg.name AS regionName,
//      s.code AS storeCode,
//      p.code AS productCode,
//      sum(r.soldPrice * r.numItemsSold) AS storeProductTotal
// ----
//
// The tabular data consists of the following:
//
// [source, cypher]
// ----
// +------------+-----------+-------------+-------------------+
// | regionName | storeCode | productCode | storeProductTotal |
// +------------+-----------+-------------+-------------------+
// | APAC       | AC-888    | PEN-1       | 20.00             |
// | APAC       | AC-888    | TOY-1       | 45.00             |
// | EMEA       | LK-709    | BOOK-2      | 10.00             |
// | EMEA       | LK-709    | TOY-1       | 40.00             |
// | EMEA       | LK-709    | BOOK-5      | 15.00             |
// | EMEA       | WW-531    | BOOK-5      | 18.00             |
// | EMEA       | WW-531    | BULB-2      | 190.00            |
// | EMEA       | WW-531    | PC-1        | 440.00            |
// +------------+-----------+-------------+-------------------+
// 8 rows
// ----
//
// Next, we read from the *SalesDetail* graph to get the store, product and region information:
//
// [source, cypher]
// ----
// MATCH (p:Product)-[:IN]->(o:Order)<-[:HAS]-(s:Store)-[:IN]->(r:Region)
// ----
//
// We now create a new graph, *SalesSummary*, containing the summarized view of the sales information across regions, products and stores:
//
// [source, cypher]
// ----
// INTO NEW GRAPH SalesSummary
// MERGE (s:Store {storeCode: s.code})
// MERGE (r:Region {name: r.name})
// MERGE (p:Product {productCode: p.code, RRP: p.RRP})
// MERGE (s)-[:IN]->(r)
// MERGE (p)-[:SOLD_IN]->(s)
//
// // Get the total amount sold for a store
// WITH storeCode, sum(storeProductTotal) AS totalSales
// // Get the total amount sold for a product
// WITH productCode, sum(storeProductTotal) AS soldTotal
//
// // Update all store nodes with the new totalSales property
// MATCH (s:Store)
// SET s.totalSales = totalSales
// WHERE s.code = storeCode
//
// // Update all product nodes with the new soldTotal property
// MATCH (p:Product)
// SET p.soldTotal = soldTotal
// WHERE p.code = productCode
//
// // Update all (:Product)-[SOLD_IN]->(:Store) relationships with the new sold property
// MATCH (p:Product)-[r:SOLD_IN]->(s:Store)
// SET r.sold = storeProductTotal
// WHERE p.code = productCode
// AND s.code = storeCode
// ----
//
// As a final step, the *SalesSummary* graph is returned, along with a high-level summarized tabular view of store sales data.
//
// [source, cypher]
// ----
// RETURN regionName,
//        storeCode,
//        sum(storeProductTotal) AS totalStoreSales
// GRAPH SalesSummary
// ----
//
// The *SalesSummary* graph is comprised of the following:
//
// image::opencypher-SalesSummary-graph.jpg[Graph,800,700]
//
// The high-level summarized tabular data consists of the following:
//
// [source, cypher]
// ----
// +------------+-----------+-----------------+
// | regionName | storeCode | totalStoreSales |
// +------------+-----------+-----------------+
// | APAC       | AC-888    | 65.00           |
// | EMEA       | LK-709    | 65.00           |
// | EMEA       | WW-531    | 648.00          |
// +------------+-----------+-----------------+
// 3 rows
// ----
//
// We note that the *SalesSummary* graph can be used to generate further high-level sales summaries, such as the total sales of a particular product (shown <<data-aggregation-external-example, here>>), as well as more detailed views.
//
// ._The full aggregation query pipeline is given by_:
// [source, cypher]
// ----
// FROM GRAPH SalesDetail AT ‘graph://...’
// MATCH (p:Product)-[r:IN]->(o:Order)<-[HAS]-(s:Store)-[:IN]->(reg:Region)
//
// WITH reg.name AS regionName,
//      s.code AS storeCode,
//      p.code AS productCode,
//      sum(r.soldPrice * r.numItemsSold) AS storeProductTotal
//
// MATCH (p:Product)-[:IN]->(o:Order)<-[:HAS]-(s:Store)-[:IN]->(r:Region)
//
// INTO NEW GRAPH SalesSummary
// MERGE (s:Store {code: s.code})
// MERGE (r:Region {name: r.name})
// MERGE (p:Product {code: p.code, RRP: p.RRP})
// MERGE (s)-[:IN]->(r)
// MERGE (p)-[:SOLD_IN]->(s)
//
// // Get the total amount sold for a store
// WITH storeCode, sum(storeProductTotal) AS totalSales
// //Get the total amount sold for a product
// WITH productCode, sum(storeProductTotal) AS soldTotal
//
// // Update all store nodes with the new totalSales property
// MATCH (s:Store)
// SET s.totalSales = totalSales
// WHERE s.code = storeCode
//
// // Update all product nodes with the new soldTotal property
// MATCH (p:Product)
// SET p.soldTotal = soldTotal
// WHERE p.code = productCode
//
// // Update all (:Product)-[SOLD_IN]->(:Store) relationships with the new sold property
// MATCH (p:Product)-[r:SOLD_IN]->(s:Store)
// SET r.sold = storeProductTotal
// WHERE p.code = productCode
// AND s.code = storeCode
//
// RETURN regionName,
//        storeCode,
//        sum(storeProductTotal) AS totalStoreSales
// GRAPH SalesSummary
// ----
//
// [[data-aggregation-external-example]]
// === Using a pipeline in an external execution context
//
// We show how a pipeline may be used in an external execution context; i.e. where processes external to the pipeline -- for example, an SQL query engine invoking a Cypher query as a graph function, or an automated business workflow system -- can be used to orchestrate externally query composition within the pipeline.
//
// Assume that the pipeline defined <<data-aggregation-example, above>> has executed and produced the *SalesSummary* graph, and that there is in scope a table, populated by some external process, containing the following list of codes (given by 'product_code') of the products of interest:
//
// [source, cypher]
// ----
// TOY -1
// BOOK-5
// BULB-2
// ----
//
// We obtain the graph and the table:
//
// [source, cypher]
// ----
// WITH product_code AS productCode GRAPH SalesSummary
// FROM GRAPH SalesSummary
// ----
//
// We then match the products in the *SalesSummary* graph with the ones from the input table, and produce a high-level report on the sales by product for only those products:
//
// [source, cypher]
// ----
// MATCH (p:Product)
// WHERE p.code = productCode
// RETURN p.code AS productCode, p.soldTotal AS totalProductSales
// ----
//
// The resulting 'sales by product' report contains:
//
// [source, cypher]
// ----
// +-------------+-------------------+
// | productCode | totalProductSales |
// +-------------+-------------------+
// | TOY-1       | 85.00             |
// | BOOK-5      | 33.00             |
// | BULB-2      | 190.00            |
// +-------------+-------------------+
// 3 rows
// ----
//



== Considerations


=== Interaction with existing features

This proposal is far reaching as it updates both the property graph model and the execution model of the language.

However, the change has been carefully designed to not change the semantics of existing queries.


=== Alternatives

A central design consideration has been wether entities should belong only to a single graph or should be shared arbitrarily between multiple graphs.
This proposal advocates a middle ground: At the data model level, entities are contained in a single graph only.
This establishes a 1:1 correspondence between entities and graphs grants great implementation freedom in terms of id space management.
At the language semantics level, cloning tracks entities that are effectively shared across graphs and treats the root original and all of its clones as the same entity in terms of equality.
This has been reflected in the re-definition of the `id` function that always returns the identity of a corresponding clone in the working graph, even for entities matched in another graph.

Instead of only returning either a table or a single graph, an earlier edition of this proposal explored to return table-graphs, i.e. both a single driving table and an associated set of multiple, named graphs.
This felt overly complicated and made it difficult to distinguish between graphs in scope and variables in scope, created the need to occasionally create dummy values (like an empty graph or driving table), and led to a more complex execution result (with potentially difficult repercussions for the network protocol).

Instead of only establishing a single working graph, an earlier edition of this proposal explored the idea of distinguishing between a graph for reading and a graph for writing.
This led to a more complex execution result, made it necessary to manage those two graphs and complicated the users mental model, and was ultimately discarded based on a use-case analysis that indicated that in practice queries would typically first select graphs for reading and then switch to writing.

Instead of introducing graphs as separate catalog objects, an earlier edition of this proposal considered graphs as values (called graphlets).
While providing great flexibility, this approach becomes very difficult to plan and statically analyze.
It also leads to intractable operations like joins between graphs.
However it may still be worthwhile to explore this idea in the future for "tiny subgraphs".


=== Syntax variations

Below is a list of potential syntax variations under discussion:

 * `DROP GRAPH` instead of `DELETE GRAPH`
 * Listing multiple graphs as an argument to `FROM` and `UPDATE` etc. could be defined as a syntax shorthand for an implied graph union between these graphs


=== What others do

SPARQL only provides basic facilities for returning graphs using `CONSTRUCT`.

SQL constructs derived tables using projection, aggregation, and filtering.

Neither Gremlin nor PGQL have developed facilities for the direct construction and manipulation of graphs.


=== Benefits to this proposal

Cypher is evolved to become a query language that is properly closed under graphs and tables.


=== Caveats to this proposal

This is a fundamental and large change to the language whose long-term consequences are difficult to assess.
