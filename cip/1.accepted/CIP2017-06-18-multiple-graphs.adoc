= CIP2017-06-18 Multiple Graphs
:numbered:
:toc:
:toc-placement: macro
:source-highlighter: codemirror

*Author:* Stefan Plantikow <stefan.plantikow@neotechnology.com>

This material is based on internal contributions of Alastair Green <alastair.green@neotechnology.com>, Mats Rydberg <mats.rydberg@neotechnology.com>, Martin Junghanns <martin.junghanns@neotechnology.com>, Tobias Lindaaker <tobias.lindaaker@neotechnology.com>, Petra Selmer <petra.selmer@neotechnology.com>

[abstract]
.Abstract
--
// This CIP proposes extending Cypher to support the construction, transformation, and querying of multiple graphs by adopting (i) the proposed multiple property graphs model, (ii) the proposed multiple graphs execution model, and (iii) by introducing new syntax for working with multiple graphs.
* [X] Graph data model
* [X] Id/stability
* [X] Graph catalog
* [X] Catalog operations
* [X] Selecting and using the working graph
* [X] Returning a graph
* [X] Projecting graphs
* [X] Disjoint graph union
* [ ] Revisit Examples
* [ ] Syntactic units / queries/ DDL chaining (stmt1; stm2)
* [ ] Scalar subqueries
* [ ] Nested subqueries
* [ ] Named queries in catalog and locally
* [ ] Named graphs in catalog and locally
* [ ] Equivalence (expressions)
--

toc::[]



== Motivation

Cypher today is a query language for property graphs that provides access to a single, global, implicit graph in order to extract, transform, and return tabular data that is derived from it.
While such returned tabular data may include graph entities (such as nodes and relationships), in essence Cypher as a language is not closed under graphs and as a consequence, Cypher queries are not yet (graph) compositional.

However it seems desirable that a language for property graphs should not only enable querying and updating a selected graph but should also support the construction and transformation of multiple graphs, ideally by utilizing a mechanism for incremental query composition.

Furthermore, adding support for working with multiple graphs has recently been identified as a frequently requested feature:

* It enables the dynamic construction of graph views (e.g. for access control)
* It allows reasoning over multiple versions of the same graph (e.g. comparing daily snapshots)
* It provides an effective grouping mechanism for naturally-partitioned data (e.g. per-continent graph)
* It is useful for combining data from disparate data sources in one system (e.g. in federation and data integration scenarios)
* It fits the paradigm of prominent analytical big-data processing systems (e.g. Apache Spark)
* It mirrors mathematical graph theory where working with multiple graphs is common

== Multiple property graphs model

The data model used here is called the *multiple property graphs data model*.
It extends the original https://github.com/opencypher/openCypher/blob/master/docs/property-graph-model.adoc[*property graph model*] with the notion of multiple graphs as outlined in the following subsections.

=== Model instance

_Definition_: A *multiple property graphs model instance* is a set of property graphs.

=== Basic definitions

_Definition_: A *label* is a symbolic string that is used for classifying nodes.

_Definition_: A *relationship type* is a symbolic string that is used for classifying relationships.

_Definition_: A *property* is a tuple consisting of a named *property key* and a *property value*.

=== Model elements

_Term_: The constituents of an instance of the multiple property graphs model are called its *model elements*.

_Definition_: An *identity* is a value that is used to identify individual model elements and to distinguish between multiple model elements from the same context.
Identities must not be `NULL` and must not be nested values that contain `NULL`.
Identities must not be model elements and must not be nested values that contain model elements.

_Term_: The constituents of a model element (including its identity) are called its *content*.

_Definition_: A *(property) graph* has a *graph identity* that uniquely identifies the graph and at least allows to distinguish it from other graphs in the same instance of the multiple property graph  model.
A property graph further consists of a set of nodes and a set of relationships that connect the nodes of the property graph.
Each property graph is contained in exactly one instance of the multiple property graphs data model.

Graphs may be either immutable or updatable.
This is not considered to be part of the content of the graph.

_Definition_: A *node* has a *node identity* that uniquely identifies the node and at least allows to distinguish it from other nodes that are contained in the same property graph.
A node further consists of a set of zero or more labels and zero or more properties with mutually different property keys.
Each node is contained in exactly one property graph.

_Definition_: A *relationship* has a *relationship identity* that uniquely identifies the relationship and at least allows to distinguish it from other relationships that are contained in the same property graph.
A relationship further consists of a *start node*, an *end node*, and exactly one relationship type, and zero or more properties with mutually different property keys.
Each relationship is contained in exactly one property graph and its start node and its end node are both contained in the same property graph as the relationship.

_Term_: Both nodes and relationships are called *entities*.

_Term_: Both node and relationship identities are called *entity identities*.

=== Reflective functions

The identities of model elements may be obtained using the following reflective functions:

The `graph(e)` function returns the *graph identity* of the graph that contains an entity `e`.

The `id(n)` function returns the *node identity* of a node `n`.

The `id(r)` function returns the *relationship identity* of a relationship `r`.



== Query processing

_Definition_: A *source program* is a piece of text that is intended to be both a syntatically valid term according to the root production rule of the grammar of the Cypher property graph query language and also a semantically valid term according to the semantic rules of the Cypher property graph query language.

_Definition_: A *query processor* is a query processing service that executes a source program  on behalf of a *client*  and provides the client with the *execution result* that describes the outcome of executing the source program.

=== Catalog

A query processor maintains exactly one *catalog*.

_Definition_: A _catalog_ is a mapping from *fully qualified graph names* to graph references.
Multiple entries in the catalog may refer to the same graph.

A fully qualified graph name should use the syntax for dotted variable identifiers and consists of an optional *graph namespace*, and a mandatory *graph name*.

Note:: In practice, a query processor might have a catalog shared by all users, or provide a different catalog for each user.
This is not considered here based on the simplifying assumption that all client requests are made by the same user.


=== Statements

_Definition_: A *statement* is a source program that is a syntatically valid term according to the root production rule of the grammar of the Cypher property graph query language.

_Definition_: A *semantically valid statement* is a statement that is valid according to the semantic rules of the Cypher property graph query language.

// A statement may either be a *single statement* or a *statement chain*.

_Definition_: A _statement_ is one of

 * *reading query* (a statement that reads and returns data)
 * *updating query* (a statement that reads, updates, and returns data)
 * *updating command* (a statement that reads and updates data but returns no data)
 * *schema command* (a statement that only updates the data schema)
 * *catalog command* (a statement that only updates the catalog)

Statements in turn consist of a chain of one ore more clauses which each may be further qualified by clause arguments, sub-clauses and sub-clause arguments.

_Term_: Clauses may be classified according to their side-effects as either _reading_, _updating_, _schema_, or _catalog clauses_.

// _Definition_: A _statement chain_ is a single statement followed by a semicolon followed by another statement.


=== Execution of client requests


==== Client requests

_Definition_: A source program together with all required parameters is called a *client request*.


==== Execution results

_Definition_: The result of executing a client request is called an *execution result*.
An execution result is one of

* a *tabular result*, i.e. a collection of records where each record has the exact same set of named fields.
Tabular results may contain duplicate results and may optionally be ordered
* a *graph result*, i.e. the contents of a graph as described by its set of nodes and relationships
* an *execution error*, i.e. a message describing the reason that prevented the query processor from executing the statement correctly


==== Request execution

Clients interact with the query processor by submitting a client request.
The source program is then executed by the query processor and an execution result is returned to the client for consumption.
An error is raised if the client request does not contain a semantically valid statement.

// ==== Execution of statement chains
//
// Statement chains are executed by executing all contained single statements in the order given.
// If execution of any contained single statement fails with an error, the execution of the whole statement fails with the same error.
// Otherwise, the query processor discards all intermediary results produced by a statement chain and only returns the execution result for the last single statement.


==== Identity validity

Identities are guaranteed to be valid for the duration of executing a statement and consuming its result.

Implementations may choose to guarantee the validity of identities across multiple client requests.

Note:: The same identity value might reference different model elements in results from executing different statements.

==== Property value validity

Implementations may choose to support the use of any Cypher value as a valid property value except for values that either are or contain model elements.
Additionally, property values must not be `NULL`.

An error is raised the client request attempts to set a property to an invalid value.

Setting the property of an entity to `NULL` is treated as if the property would have been removed.


==== Returning graph model elements

If an execution result that is returned _to the client_ contains a graph model element, this graph model element is returned together with its content at the time of terminating the query (i.e. the client always receives the current content of all graph model elements).

Note:: Additionally, a result may contain implementation specific metadata like a summary of performed update activity (e.g. the number of nodes created) or a detailed query plan.


=== Working graph

Most Cypher clauses operate within the context of a *working graph*, by reading or updating it.

_Definition_: The _working graph_ is a reference to a graph that is maintained during statement execution.
The working graph is optional and may be unset at the start of executing a statement.

The working graph may either reference a graph in the catalog or may reference a graph that was dynamically constructed during statement execution.

A query processor may choose to establish an *initial working graph* for each executed statement.
The details of this are left to implementations.

If a query processor has not established an initial working graph (i.e. the working graph is unset) and the statement fails to set a working graph explicitly before attempting to operate on the working graph, an error is raised.



== Graph operations in queries

The working graph may be operated on in the following ways:

* The working graph can be changed by selecting a graph that is known by the catalog.
* The working graph may be returned as a query result
* The working graph can be changed by constructing a new graph
* The working graph can be changed by constructing a disjoint graph union


=== Selecting the working graph from the catalog for querying

The working graph may be changed for all subsequent querying clauses using:

[source, cypher]
----
FROM < graph-name >
FROM GRAPH
----

`<graph-name>` is expected to be the name of a graph in the catalog.
If `<graph-name>` is not the name of a graph in the catalog, an error is raised.
It is an error to perform an updating operation on a working graph that was introduced using `FROM [GRAPH]`.

Additionally, `FROM GRAPH` may be used to select the working graph for further read-only operations.


=== Selecting the working graph from the catalog for updating

The working graph may be changed for all subsequent querying and updating clauses using:

[source, cypher]
----
UPDATE < graph-name >
----

`<graph-name>` is expected to be the name of a graph in the catalog.
If `<graph-name>` is not the name of a graph in the catalog, an error is raised.
It is an error to not perform at least a single updating operation on a working graph that was introduced using `UPDATE [GRAPH]`.

Additionally, `UPDATE GRAPH` may be used to select the working graph for further updating operations.


=== Returning a graph result

The working graph may be returned as an execution result using:

[source, cypher]
----
RETURN GRAPH
----

Additionally, the following syntactic form is supported for selecting the working graph from the catalog and returning it at the same time:

[source, cypher]
----
RETURN GRAPH < graph-name >
----

Graphs are always returned by reference during execution inside the query processor.
This does not affect the rules on returning model elements together with their content to the client which ensure that a graph result will be returned by value to the client.


=== Constructing a graph

*Graph construction* dynamically constructs a new working graph in order to query it, store it in the catalog, or return it to the client.

Graph construction is the dual operation to graph matching: While graph matching extracts pattern instances into variable bindings from the working graph, graph construction builds a new working graph from variable bindings.

All nodes and relationships in the newly constructed graph have new entity identities and are different from any previously matched entities.

The general form of graph construction is:

[source, cypher]
----
CONSTRUCT
  [ON GRAPH]
  [ON < graph-name-list >]
  [CLONE < cloned-entities >]
  [NEW < patterns >]
  [YIELD < return-items >|*]
----

Graph construction supports sub-clauses for the *addition of new entities*, the *cloning of existing entities*, and the optional *yielding of result variable bindings*.

At least either the `ON` sub-clause, the `CLONE` sub-clause, or the `NEW` sub-clause must be present in `CONSTRUCT`.

A single statement may not end in a `CONSTRUCT` clause (invalid syntax).


==== Addition of new entities

The `NEW <patterns>` sub-clause may be used to construct new nodes and relationships in the constructed graph in the same way as the `CREATE` clause allows to create new nodes and relationships in existing graphs.

`NEW` creates exactly one pattern instance in the new graph for each input record.


==== Cloned entities

In order to reconstruct subgraph structures from other graphs in the new graph, `CONSTRUCT` supports the addition of *cloned entities* in the new graph.

*Cloning* ensures that exactly one new entity (called a *clone*) is created in the new graph for a given cloned entity (called its *original*) from a source graph.
If the same original is cloned multiple times this will still only create one clone in the new graph.
Every clone has exactly the same labels or relationship type as well as the same properties as the original (i.e. a clone can be seen as a "representative" of the original in the new graph).
Cloning a relationship implicitly clones its start node and its end node and uses them as start node and end node of the relationship clone.

The `ON GRAPH` sub-clause may be used to clone all nodes and relationships from the working graph into the new graph.

The `ON < graph-name-list >` sub-clause may be used to clone all nodes and relationships from the given graphs in the catalog into the new graph.

The `CLONE < return-items >` sub-clause may be used to clone entities and bind the cloned entities to new variable names or shadow already bound variables.
`CLONE` constructs cloned entities for each input record subject to the following rules:

 * Cloning a single, already bound variable rebinds the variable. In other words `CLONE a` is interpreted as `CLONE a AS a`.
 No other form of `CLONE` may rebind an already bound variable
 * Cloning a nested value (like a path) implicitly clones all contained nodes and relationships


==== Yielding result variable bindings

The `YIELD *|<return-items>` sub-clause may be used to preserve the current record cardinality and optionally either preserve or shadow input variable bindings as well as introduce new variable bindings.

`YIELD *` may be used to yield the variable bindings for all cloned and newly created entities.
This will preserve the current record cardinality but may shadow input variable bindings as well as introduce new variable bindings.

`YIELD <return-items>` may be used to yield variable bindings for explicitly selected cloned and newly created entities.
This will preserve the current record cardinality but may shadow input variable bindings as well as introduce new variable bindings.


==== Not yielding result variable bindings

If a `CONSTRUCT` clause is not ending in a `YIELD` sub-clause, the current record cardinality and all input variable bindings are dropped.
The next clause then proceeds in the newly constructed working graph on a single record with no fields.


=== Disjoint graph union

The disjoint graph union of two graphs may be computed using the following syntax:

[source, cypher]
----
< query-1 >
RETURN GRAPH
UNION ALL
< query-2 >
RETURN GRAPH
----

The resulting union graph consists of clones of all entities from the two input graphs.



== Creating and administrating graphs in the catalog


=== Creating empty graphs

Creating a new, empty graph in the catalog is done using the new catalog command `CREATE GRAPH <graph-name>`.
If `<graph-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Creating new graphs and populating them from a query

`CREATE GRAPH <graph-name>` may be optionally followed by a subquery that returns a graph.
In that case, a new graph `<graph-name>` is created in the catalog for the graph returned by the subquery.
If `<graph-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Delete graph

The catalog command `DELETE GRAPH <graph-name>` deletes the graph with the name `<graph-name>` from the catalog.
If `<graph-name>` is not the name of a graph that already exists in the catalog, an error is raised.


=== Copy graph

The catalog command `COPY <old-name> TO <new-name>` copies the content and the schema of the graph with the name `<old-name>` in the catalog to a new graph with the name `<new-name>` in the catalog.
If `<old-name>` is not the name of a graph that already exists in the catalog, an error is raised.
If `<new-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Rename graph

The catalog command  `RENAME <old-name> TO <new-name>` removes the graph with the name `<old-name>` from the catalog and adds it as a new graph with the name `<new-name>` in the catalog.
If `<old-name>` is not the name of a graph that already exists in the catalog, an error is raised.
If `<new-name>` is the name of a graph that already exists in the catalog, an error is raised.


=== Truncating graphs

The catalog command `TRUNCATE <graph-name>` truncates the graph with the name `<graph-name` in the catalog.

Truncating a graph deletes all its nodes and relationships but retains any additional schema information like constraints.

// == Examples
//
// The following examples are intended to show how multiple graphs may be used, and focus on syntax.
// We show two fully worked-through examples <<data-integration-example, here>> and <<data-aggregation-example, here>>, describing and illustrating every step of the pipeline in detail.
//
// === A template for a multiple graph pipeline
// [source, cypher]
// ----
// // Query input signature: Records with fields 'a', 'b' and two graphs 'g1', 'g2'
// WITH a, b GRAPHS g1, g2
//
// // Sets source and target graph for the following statements by resolving the given physical address
// // (The name of this new graph will be system generated)
// FROM GRAPH AT 'graph://...'
//
// // Creates and sets new target graph for the following statements at the given physical address
// INTO NEW GRAPH result AT 'graph://...'
//
// // Return records with 'a', 'b' and three graphs 'result', 'g1', 'g2' (query output signature)
// // Source graph for future reads is again the default graph, the target graph for future writes is 'result'
// RETURN a, b GRAPHS result, g1, g2
// ----
//
// === A template for pipelining and interleaving queries
//
// [source, cypher]
// ----
// WITH a, b GRAPHS g1, g2 ... // First query
// WITH GRAPHS g3, g4 ...      // Second query over first query
// RETURN c, d GRAPHS g5       // Third query over second query over first query
// ----
//
// === Creating and returning a new graph and fields: a simple example
//
// [source, cypher]
// ----
// FROM GRAPH persons AT 'graph://...'
// MATCH (a:Person)-[r:KNOWS]->(b:Person)
// MATCH (a)-[:LIVES_IN->(c:City)<-[:LIVES_IN]-(b)
// INTO NEW GRAPH berlin
// CREATE (a)-[:FRIEND]->(b) WHERE c.name = "Berlin"
// INTO NEW GRAPH santiago
// CREATE (a)-[:FRIEND]->(b) WHERE c.name = "Santiago"
// FROM DEFAULT GRAPH
// RETURN c.name AS city, count(r) AS num_friends GRAPHS berlin, santiago
// ----
//
// === Creating a new graph, switching contexts and returning a graph
//
// [source, cypher]
// ----
// // Set scope to whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data
// MATCH (a:Person)-[:KNOWS]->(b:Person)-[:KNOWS]->(c:Person) WHERE NOT (a)--(c)
//
// // Create a temporary named graph,
// INTO NEW GRAPH recommendations
// // containing existing nodes and new rels ...
// CREATE (a)-[:POSSIBLE_FRIEND]->(c)
// // ... and finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// // Switch context to named graph.
// FROM GRAPH recommendations
// MATCH (a:Person)-[e:POSSIBLE_FRIEND]->(b:Person)
// // Return tabular and graph output
// RETURN a.name, b.name, count(e) AS cnt
//     ORDER BY cnt DESC
//     GRAPH recommendations
// ----
//
// === Using a pipeline of temporary graphs to process and return a subgraph
//
// [source, cypher]
// ----
// // Set scope to the whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data.
// MATCH (a:Person)-[:IS_LOCATED_IN]->(c:City),
//       (c)->[:IS_LOCATED_IN]->(co:Country),
//       (a)-[e:KNOWS]-(b)
//
// // Create a new temporary named graph,
// INTO NEW GRAPH sn_updated
// // add previous matches to new graph,
// CREATE (a)-[e]-(b)
// // update existing nodes.
// SET a.country = cn.name
// // ... and finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// FROM GRAPH sn_updated
// MATCH (a:Person)-[e:KNOWS]->(b:Person)
// WITH a.country AS a_country, b.country AS b_country, count(a) AS a_cnt, count(b) AS b_cnt, count(e) AS e_cnt
// INTO NEW GRAPH rollup
// MERGE (:Persons {country: a_country, cnt: a_cnt})-[:KNOW {cnt: e_cnt}]->(:Persons {country: b_country, cnt: b_cnt})
//
// // Return final graph output
// RETURN GRAPH rollup
// ----
//
// === A more complex pipeline: using and persisting multiple graphs
//
// [source, cypher]
// ----
// // Set scope to the whole social network ...
// FROM GRAPH AT 'graph://social-network'
// // .. and match some data.
// MATCH (a:Person)-[e]->(b:Person),
//       (a)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c:Country {name: ‘Sweden’}),
//       (b)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c)
// // Create a persistent graph at 'graph://social-network/swe'
// INTO NEW GRAPH sweden_people AT './swe'
// // connecting persons that live in the same city in Sweden.
// CREATE (a)-[e]->(b)
//
// // Finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// MATCH (a:Person)-[e]->(b:Person),
//       (a)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c:Country {name: ‘Germany’}),
//       (b)-[:LIVES_IN]->()->[:IS_LOCATED_IN]-(c)
// // Create a persistent graph at 'graph://social-network/ger'
// INTO NEW GRAPH german_people AT './ger'
// // connecting persons that live in the same city in Germany.
// CREATE (a)-[e]->(b)
//
// // Finally discard all tabular data and cardinality
// WITH GRAPHS *
//
// // Start query on the 'sweden_people' graph
// FROM GRAPH sweden_people
// MATCH p=(a)--(b)--(c)--(a) WHERE NOT (a)--(c)
// // Create a temporary graph 'swedish_triangles'
// INTO NEW GRAPH swedish_triangles
// MERGE p
//
// // and return it together with a count of its content
// RETURN count(p) AS num_triangles GRAPHS swedish_triangles, sweden_people, german_people
// ----
//
// [[data-integration-example]]
// === A complete example illustrating a data integration scenario
//
// Assume we have two graphs, *ActorsFilmsCities* and *Events*, each of which is contained in a separate location.
// This example will show how these two graphs can be integrated into a single graph.
//
// The *ActorsFilmsCities* graph models the following entities:
//
// * Actors and people fulfilling other roles in the film-industry.
// * Films in which they acted, or directed, or for which they wrote the soundtrack.
// * Cities in which they were born.
// * The relationships between family members and colleagues.
//
// Each node is labelled and contains one or two properties (where `YOB` stands for 'year of birth'), and each relationship of type `ACTED_IN` has a `charactername` property indicating the name of the character the relevant `Actor` played in the `Film`.
//
// image::opencypher-PersonActorCityFilm-graph.jpg[Graph,800,650]
//
// The other graph, *Events*, models information on events.
// Each event is linked to an event type by an `IS_A` relationship, to a year by an `IN_YEAR` relationship, and to a city by an `IN_CITY` relationship.
// For example, the _Battle of Britain_ event is classified as a _War Event_, occurred in the year _1940_, and took place in _London_.
//
// In contrast to the *ActorsFilmsCities* graph, *Events* contains no labels on any node, no properties on any relationship, and only a single `value` property on each node.
// *Events* can be considered to be a snapshot of data from an RDF graph, in the sense that every node has one and only one value; i.e. in contrast to a property graph, an RDF graph has properties on neither nodes nor relationships.
// (For easier visibility, we have coloured accordingly the cities and city-related relationships, event types and event-type relationships, and year and year-related relationships.)
//
// image::opencypher-Events-graph.jpg[Graph,800,600]
//
// The aims of the data integration exercise are twofold:
//
// * Create and persist to disk (for future use) a new graph, *PersonCityEvents*, containing an amalgamation of data from *ActorsFilmsCities* and *Events*.
// *PersonCityEvents* must contain all the event information from *Events*, and only `Person` nodes connected to `City` nodes from *ActorsFilmsCities*.
//
// * Create and return a temporary graph, *Temp-PersonCityCrimes*.
// *Temp-PersonCityCrimes* must contain a subset of the data from *PersonCityEvents*, consisting only of the criminal events, their associated `City` nodes, and `Person` nodes associated with the `City` nodes.
//
// ==== Step 1
//
// The first action to take in our data integration exercise is to set the source graph to *ActorsFilmsCities*, for which we need to provide the physical address:
//
// [source, cypher]
// ----
// FROM GRAPH ActorsFilmsCities AT 'graph://actors_films_cities...'
// ----
//
// Next, match all `Person` nodes who have a `BORN_IN` relationship to a `City`:
//
// [source, cypher]
// ----
// MATCH (p:Person)-[:BORN_IN]->(c:City)
// ----
//
// Create the new graph *PersonCityEvents*, persist it to _some-location_, and set it as the target graph:
//
// [source, cypher]
// ----
// INTO NEW GRAPH PersonCityEvents AT 'some-location'
// ----
//
// Write the subgraph induced by the `MATCH` clause above into *PersonCityEvents*:
//
// [source, cypher]
// ----
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (p)-[:BORN_IN]->(c)
// ----
//
// Putting all these statements together, we get:
//
// ._Query sequence for Step 1_:
// [source, cypher]
// ----
// FROM GRAPH ActorsFilmsCities AT 'graph://actors_films_cities...'
// MATCH (p:Person)-[:BORN_IN]->(c:City)
// INTO NEW GRAPH PersonCityEvents AT 'some-location'
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (p)-[:BORN_IN]->(c)
//
// // Discard all tabular data and cardinality
// WITH GRAPHS *
// ----
//
// At this stage, *PersonCityEvents* is given by:
//
// image::opencypher-PersonCity-graph.jpg[Graph,600,400]
//
// ==== Step 2
//
// The next stage in the pipeline is to add the events information from *Events* to *PersonCityEvents*.
//
// Firstly, the source graph is set to *Events*, for which we need to provide the physical address:
//
// [source, cypher]
// ----
// FROM GRAPH Events AT 'graph://events...'
// ----
//
// At this point, the *Events* graph is in scope.
//
// All the events information -- the event itself, its type, the year in which it occurred, and the city in which it took place -- is matched:
//
// [source, cypher]
// ----
// MATCH (c)<-[:IN_CITY]-(e)-[:IN_YEAR]->(y),
//       (e)-[:IS_A]->(et {value: 'Criminal Event'})
//
// // Do matches for all other event types: Public Event, War Event....
// ...
// ----
//
// The target graph is set to the *PersonCityEvents* graph (created earlier):
//
// [source, cypher]
// ----
// INTO GRAPH PersonCityEvents
// ----
//
// Using the results from the `MATCH` clause, create a subgraph with more intelligible semantics through the transformation of the events information into a less verbose form through greater use of node-level properties.
//  Write the subgraph to *PersonCityEvents*.
//
// [source, cypher]
// ----
// MERGE (c:City {name: c.value})
// MERGE (e {title: e.value, year: y.value})
// MERGE (e)-[:HAPPENED_IN]->(c)
// SET e :WarEvent
//
// // Do for all remaining event types
// ...
// ----
//
// Putting all these statements together, we get:
//
// ._Query sequence for Step 2_:
// [source, cypher]
// ----
// FROM GRAPH Events AT 'graph://events...'
// MATCH (c)<-[:IN_CITY]-(e)-[:IN_YEAR]->(y),
//       (e)-[:IS_A]->(et {value: 'Criminal Event'})
//
// // Do matches for all other event types: Public Event, War Event....
// ...
// INTO GRAPH PersonCityEvents
// MERGE (c:City {name: c.value})
// MERGE (e {title: e.value, year: y.value})
// MERGE (e)-[:HAPPENED_IN]->(c)
// SET e :WarEvent
//
// // Do for all remaining event types
// ...
//
// // Discard all tabular data and cardinality
// WITH GRAPHS *
// ----
//
// *PersonCityEvents* now contains the following data:
//
// image::opencypher-PersonCityEvents-graph.jpg[Graph,800,700]
//
// ==== Step 3
//
// The last step in the data integration pipeline is the creation of a new, temporary graph, *Temp-PersonCityCrimes*, which is to be populated with the subgraph of all the criminal events and associated nodes from *PersonCityEvents*.
//
// Set *PersonCityEvents* to be in scope:
//
// [source, cypher]
// ----
// FROM GRAPH PersonCityEvents
// ----
//
// Next, obtain the subgraph of all criminal events -- i.e. nodes labelled with `CriminalEvent` -- and their associated `City` nodes, and `Person` nodes associated with the `City` nodes:
//
// [source, cypher]
// ----
// MATCH (ce:CriminalEvent)-[:HAPPENED_IN]->(c:City)<-[:BORN_IN]-(p:Person)
// ----
//
// Create the new, temporary graph *Temp-PersonCityCrimes*, and set it as the target graph:
//
// [source, cypher]
// ----
// INTO NEW GRAPH Temp-PersonCityCrimes
// ----
//
// Write the subgraph acquired earlier to *Temp-PersonCityCrimes*.
//
// [source, cypher]
// ----
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (ce:CriminalEvent {title: ce.title, year: ce.year})
// MERGE (p)-[:BORN_IN]->(c)
// MERGE (ce)-[:HAPPENED_IN]->(c)
// ----
//
// Putting all these statements together, we get:
//
// ._Query sequence for Step 3_:
// [source, cypher]
// ----
// FROM PersonCityEvents
// MATCH (ce:CriminalEvent)-[:HAPPENED_IN]->(c:City)<-[:BORN_IN]-(p:Person)
// INTO NEW GRAPH Temp-PersonCityCrimes
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (ce:CriminalEvent {title: ce.title, year: ce.year})
// MERGE (p)-[:BORN_IN]->(c)
// MERGE (ce)-[:HAPPENED_IN]->(c)
//
// ----
//
// And, as the final step of the entire data integration pipeline, return *Temp-PersonCityCrimes*, which is comprised of the following data:
//
// image::opencypher-PersonCityCriminalEvents-graph.jpg[Graph,700,550]
//
// ._The full data integration query pipeline is given by_:
// [source, cypher]
// ----
// FROM GRAPH ActorsFilmsCities AT 'graph://actors_films_cities...'
// MATCH (p:Person)-[:BORN_IN]->(c:City)
// INTO NEW GRAPH PersonCityEvents AT 'some-location'
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (p)-[:BORN_IN]->(c)
//
// WITH GRAPHS *
//
// FROM GRAPH Events AT 'graph://events...'
// MATCH (c)<-[:IN_CITY]-(e)-[:IN_YEAR]->(y),
//       (e)-[:IS_A]->(et {value: 'Criminal Event'})
//
// // Do matches for all other event types: Public Event, War Event....
// ...
// INTO GRAPH PersonCityEvents
// MERGE (c:City {name: c.value})
// MERGE (e {title: e.value, year: y.value})
// MERGE (e)-[:HAPPENED_IN]->(c)
// SET e :WarEvent
//
// // Do for all remaining event types
// ...
//
// WITH GRAPHS *
//
// FROM GRAPH PersonCityEvents
// MATCH (ce:CriminalEvent)-[:HAPPENED_IN]->(c:City)<-[:BORN_IN]-(p:Person)
// INTO NEW GRAPH Temp-PersonCityCrimes
// MERGE (p:Person {name: p.name, YOB: p.YOB})
// MERGE (c:City {name: c.name})
// MERGE (ce:CriminalEvent {title: ce.title, year: ce.year})
// MERGE (p)-[:BORN_IN]->(c)
// MERGE (ce)-[:HAPPENED_IN]->(c)
//
// RETURN GRAPHS Temp-PersonCityCrimes
// ----
//
// [[data-aggregation-example]]
// === Using a pipeline to perform aggregations and return tabular data and graphs
//
// This example shows how to aggregate detailed sales data within a graph -- in effect, performing a 'roll-up' -- in order to obtain a high-level summarized view of the data, stored and returned in another graph, as well as returning an even higher-level view as an executive report.
// The summarized graph may be used to draw further high-level reports, but may also be used to undertake 'drill-down' actions by probing into the graph to extract more detailed information.
//
// Assume we have the graph *SalesDetail*, representing the sale of products in stores across various regions:
//
// image::opencypher-SalesDetail-graph.jpg[Graph,800,700]
//
// This models the following entities:
//
// * Regions may have many stores.
// * Stores:
// ** A store is identified by a unique `code`.
// ** A store is contained in exactly one region.
// ** A store may have multiple orders.
// * Products:
// ** A product is identified by a unique `code`.
// ** A product has a `RRP` property (Recommended Retail Price).
// ** A product may appear in one or more orders as a product _item_.
// * Sales orders:
// ** An order is identified by a unique order number, given by `num`.
// ** The `YYYYMM` property represents the year and month portion of the date of the order.
// ** An order is associated with exactly one store and contains one or more product items, representing the fact that the product item was sold in the store and is a part of the order.
// ** The relationship of between an order and a product contains the following properties:
// *** `soldPrice`: the price at which the product item was actually sold (usually lower than the product's RRP).
// *** `numItemsSold`: the number of the actual product items sold in the order.
//
// The following pipeline will create a summarized view of this data, and store it in a new summary graph called *SalesSummary*.
//
// We begin by referencing the *SalesDetail* graph, and matching on all products in all orders for all stores in all regions.
//
// [source, cypher]
// ----
// FROM GRAPH SalesDetail AT ‘graph://...’
// MATCH (p:Product)-[r:IN]->(o:Order)<-[HAS]-(s:Store)-[:IN]->(reg:Region)
// ----
//
// We aggregate the (tabular) data across all orders in order to obtain the total sales amount grouped by the product, store and region, and alias this value as `storeProductTotal`.
// As this tabular data is required to populate the summary graph later on, we pass it further down the pipeline:
//
// [source, cypher]
// ----
// WITH reg.name AS regionName,
//      s.code AS storeCode,
//      p.code AS productCode,
//      sum(r.soldPrice * r.numItemsSold) AS storeProductTotal
// ----
//
// The tabular data consists of the following:
//
// [source, cypher]
// ----
// +------------+-----------+-------------+-------------------+
// | regionName | storeCode | productCode | storeProductTotal |
// +------------+-----------+-------------+-------------------+
// | APAC       | AC-888    | PEN-1       | 20.00             |
// | APAC       | AC-888    | TOY-1       | 45.00             |
// | EMEA       | LK-709    | BOOK-2      | 10.00             |
// | EMEA       | LK-709    | TOY-1       | 40.00             |
// | EMEA       | LK-709    | BOOK-5      | 15.00             |
// | EMEA       | WW-531    | BOOK-5      | 18.00             |
// | EMEA       | WW-531    | BULB-2      | 190.00            |
// | EMEA       | WW-531    | PC-1        | 440.00            |
// +------------+-----------+-------------+-------------------+
// 8 rows
// ----
//
// Next, we read from the *SalesDetail* graph to get the store, product and region information:
//
// [source, cypher]
// ----
// MATCH (p:Product)-[:IN]->(o:Order)<-[:HAS]-(s:Store)-[:IN]->(r:Region)
// ----
//
// We now create a new graph, *SalesSummary*, containing the summarized view of the sales information across regions, products and stores:
//
// [source, cypher]
// ----
// INTO NEW GRAPH SalesSummary
// MERGE (s:Store {storeCode: s.code})
// MERGE (r:Region {name: r.name})
// MERGE (p:Product {productCode: p.code, RRP: p.RRP})
// MERGE (s)-[:IN]->(r)
// MERGE (p)-[:SOLD_IN]->(s)
//
// // Get the total amount sold for a store
// WITH storeCode, sum(storeProductTotal) AS totalSales
// // Get the total amount sold for a product
// WITH productCode, sum(storeProductTotal) AS soldTotal
//
// // Update all store nodes with the new totalSales property
// MATCH (s:Store)
// SET s.totalSales = totalSales
// WHERE s.code = storeCode
//
// // Update all product nodes with the new soldTotal property
// MATCH (p:Product)
// SET p.soldTotal = soldTotal
// WHERE p.code = productCode
//
// // Update all (:Product)-[SOLD_IN]->(:Store) relationships with the new sold property
// MATCH (p:Product)-[r:SOLD_IN]->(s:Store)
// SET r.sold = storeProductTotal
// WHERE p.code = productCode
// AND s.code = storeCode
// ----
//
// As a final step, the *SalesSummary* graph is returned, along with a high-level summarized tabular view of store sales data.
//
// [source, cypher]
// ----
// RETURN regionName,
//        storeCode,
//        sum(storeProductTotal) AS totalStoreSales
// GRAPH SalesSummary
// ----
//
// The *SalesSummary* graph is comprised of the following:
//
// image::opencypher-SalesSummary-graph.jpg[Graph,800,700]
//
// The high-level summarized tabular data consists of the following:
//
// [source, cypher]
// ----
// +------------+-----------+-----------------+
// | regionName | storeCode | totalStoreSales |
// +------------+-----------+-----------------+
// | APAC       | AC-888    | 65.00           |
// | EMEA       | LK-709    | 65.00           |
// | EMEA       | WW-531    | 648.00          |
// +------------+-----------+-----------------+
// 3 rows
// ----
//
// We note that the *SalesSummary* graph can be used to generate further high-level sales summaries, such as the total sales of a particular product (shown <<data-aggregation-external-example, here>>), as well as more detailed views.
//
// ._The full aggregation query pipeline is given by_:
// [source, cypher]
// ----
// FROM GRAPH SalesDetail AT ‘graph://...’
// MATCH (p:Product)-[r:IN]->(o:Order)<-[HAS]-(s:Store)-[:IN]->(reg:Region)
//
// WITH reg.name AS regionName,
//      s.code AS storeCode,
//      p.code AS productCode,
//      sum(r.soldPrice * r.numItemsSold) AS storeProductTotal
//
// MATCH (p:Product)-[:IN]->(o:Order)<-[:HAS]-(s:Store)-[:IN]->(r:Region)
//
// INTO NEW GRAPH SalesSummary
// MERGE (s:Store {code: s.code})
// MERGE (r:Region {name: r.name})
// MERGE (p:Product {code: p.code, RRP: p.RRP})
// MERGE (s)-[:IN]->(r)
// MERGE (p)-[:SOLD_IN]->(s)
//
// // Get the total amount sold for a store
// WITH storeCode, sum(storeProductTotal) AS totalSales
// //Get the total amount sold for a product
// WITH productCode, sum(storeProductTotal) AS soldTotal
//
// // Update all store nodes with the new totalSales property
// MATCH (s:Store)
// SET s.totalSales = totalSales
// WHERE s.code = storeCode
//
// // Update all product nodes with the new soldTotal property
// MATCH (p:Product)
// SET p.soldTotal = soldTotal
// WHERE p.code = productCode
//
// // Update all (:Product)-[SOLD_IN]->(:Store) relationships with the new sold property
// MATCH (p:Product)-[r:SOLD_IN]->(s:Store)
// SET r.sold = storeProductTotal
// WHERE p.code = productCode
// AND s.code = storeCode
//
// RETURN regionName,
//        storeCode,
//        sum(storeProductTotal) AS totalStoreSales
// GRAPH SalesSummary
// ----
//
// [[data-aggregation-external-example]]
// === Using a pipeline in an external execution context
//
// We show how a pipeline may be used in an external execution context; i.e. where processes external to the pipeline -- for example, an SQL query engine invoking a Cypher query as a graph function, or an automated business workflow system -- can be used to orchestrate externally query composition within the pipeline.
//
// Assume that the pipeline defined <<data-aggregation-example, above>> has executed and produced the *SalesSummary* graph, and that there is in scope a table, populated by some external process, containing the following list of codes (given by 'product_code') of the products of interest:
//
// [source, cypher]
// ----
// TOY -1
// BOOK-5
// BULB-2
// ----
//
// We obtain the graph and the table:
//
// [source, cypher]
// ----
// WITH product_code AS productCode GRAPH SalesSummary
// FROM GRAPH SalesSummary
// ----
//
// We then match the products in the *SalesSummary* graph with the ones from the input table, and produce a high-level report on the sales by product for only those products:
//
// [source, cypher]
// ----
// MATCH (p:Product)
// WHERE p.code = productCode
// RETURN p.code AS productCode, p.soldTotal AS totalProductSales
// ----
//
// The resulting 'sales by product' report contains:
//
// [source, cypher]
// ----
// +-------------+-------------------+
// | productCode | totalProductSales |
// +-------------+-------------------+
// | TOY-1       | 85.00             |
// | BOOK-5      | 33.00             |
// | BULB-2      | 190.00            |
// +-------------+-------------------+
// 3 rows
// ----
//
== Interaction with existing features

This proposal is far reaching as it changes both the property graph model and the execution model of the language.

However, the change has been carefully designed to not change the semantics of existing queries.

== Alternatives

The scope of this CIP could be reduced by not separating between the source and target graph.

== What others do

SPARQL only provides basic facilities for returning graphs using `CONSTRUCT`.

Neither Gremlin nor PGQL have developed facilities for the direct construction and manipulation of graphs.

== Benefits to this proposal

Cypher is evolved to become a query language that is properly closed under graphs.

== Caveats to this proposal

This is a fundamental and large change to the language whose long-term consequences are difficult to assess.
